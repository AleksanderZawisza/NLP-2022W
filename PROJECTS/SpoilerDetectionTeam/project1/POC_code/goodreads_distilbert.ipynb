{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c411ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "143402it [00:07, 20024.11it/s]\n",
      "17926it [00:00, 37434.80it/s]\n",
      "17926it [00:01, 13430.38it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import urllib.request\n",
    "import os\n",
    "import json\n",
    "import gzip\n",
    "from transformers import create_optimizer\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from datasets import Dataset\n",
    "\n",
    "DATA_PATH =  \"./data\"\n",
    "\n",
    "urls = [\n",
    "    \"https://spoiler-datasets.s3.eu-central-1.amazonaws.com/goodreads_balanced-train.json.gz\",\n",
    "    \"https://spoiler-datasets.s3.eu-central-1.amazonaws.com/goodreads_balanced-val.json.gz\",\n",
    "    \"https://spoiler-datasets.s3.eu-central-1.amazonaws.com/goodreads_balanced-test.json.gz\"\n",
    "]\n",
    "\n",
    "FORCE_REDOWNLOAD = False\n",
    "\n",
    "goodreads_train = []\n",
    "goodreads_val = []\n",
    "goodreads_test = []\n",
    "\n",
    "for goodreads_list, url in zip(\n",
    "        [goodreads_train, goodreads_val, goodreads_test], urls):\n",
    "    file = f\"{DATA_PATH}/goodreads/{url.rsplit('/', 1)[-1]}\"\n",
    "    if not os.path.exists(file) or FORCE_REDOWNLOAD:\n",
    "        urllib.request.urlretrieve(url, file)\n",
    "\n",
    "    with gzip.open(file, \"rb\") as f:\n",
    "        for line in tqdm(f):\n",
    "            goodreads_list.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01427faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-24 19:07:12.817799: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-24 19:07:13.437893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38419 MB memory:  -> device: 0, name: A100-SXM4-40GB, pci bus id: 0000:07:00.0, compute capability: 8.0\n",
      "2022-11-24 19:07:14.524064: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['activation_13', 'vocab_projector', 'vocab_layer_norm', 'vocab_transform']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier', 'pre_classifier', 'dropout_19']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, )\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_function(data):\n",
    "    return tokenizer(data[\"text\"], truncation=True)\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name, dropout=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "658c085a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "441e13aa3ca54a1a87abe95efc0c14f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/144 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efcb86cf03a64f52a1700a252da8aaff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c103f58b4d4da9a6813bf6a9bfd4cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_tf_dataset(goodreads_list):\n",
    "    tokenized_goodreads = Dataset.from_list([\n",
    "        {'text': ''.join(y[1] for y in x['review_sentences']), 'label': x['has_spoiler']}\n",
    "        for x in goodreads_list\n",
    "        ]).map(preprocess_function, batched=True)\n",
    "    return model.prepare_tf_dataset(\n",
    "        tokenized_goodreads, shuffle=True, batch_size=32, collate_fn=data_collator\n",
    "    )\n",
    "\n",
    "tf_goodreads_train = create_tf_dataset(goodreads_train)\n",
    "tf_goodreads_val = create_tf_dataset(goodreads_val)\n",
    "tf_goodreads_test = create_tf_dataset(goodreads_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "548ba89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "batches_per_epoch = len(goodreads_train) // batch_size\n",
    "\n",
    "total_train_steps = int(batches_per_epoch * num_epochs)\n",
    "\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr=2e-5, num_warmup_steps=0,\n",
    "    num_train_steps=total_train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "994510cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for w in model.get_layer('distilbert').weights:\n",
    "#     w._trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56dba323",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BalancedSparseCategoricalAccuracy(tf.keras.metrics.SparseCategoricalAccuracy):\n",
    "    def __init__(self, name='balanced_sparse_categorical_accuracy', dtype=None):\n",
    "        super().__init__(name, dtype=dtype)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_flat = y_true\n",
    "        if y_true.shape.ndims == y_pred.shape.ndims:\n",
    "            y_flat = tf.squeeze(y_flat, axis=[-1])\n",
    "        y_true_int = tf.cast(y_flat, tf.int32)\n",
    "\n",
    "        cls_counts = tf.math.bincount(y_true_int)\n",
    "        cls_counts = tf.math.reciprocal_no_nan(tf.cast(cls_counts, self.dtype))\n",
    "        weight = tf.gather(cls_counts, y_true_int)\n",
    "        return super().update_state(y_true, y_pred, sample_weight=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9168324e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer,\n",
    "             metrics=['accuracy', BalancedSparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0ee32bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=f\"./checkpoints/best_val_model_{model_name}\",\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d520b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = tf.keras.callbacks.CSVLogger(f'goodreads_fit_log_{model_name}.csv', append=True, separator=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8de43aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4481/4481 [==============================] - 1016s 225ms/step - loss: 0.4441 - accuracy: 0.7865 - balanced_sparse_categorical_accuracy: 0.7869 - val_loss: 0.4201 - val_accuracy: 0.7989 - val_balanced_sparse_categorical_accuracy: 0.7994\n",
      "Epoch 2/3\n",
      "4481/4481 [==============================] - 1004s 224ms/step - loss: 0.3735 - accuracy: 0.8286 - balanced_sparse_categorical_accuracy: 0.8286 - val_loss: 0.4169 - val_accuracy: 0.8084 - val_balanced_sparse_categorical_accuracy: 0.8084\n",
      "Epoch 3/3\n",
      "4481/4481 [==============================] - 1005s 224ms/step - loss: 0.3239 - accuracy: 0.8561 - balanced_sparse_categorical_accuracy: 0.8560 - val_loss: 0.4444 - val_accuracy: 0.8061 - val_balanced_sparse_categorical_accuracy: 0.8077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fecb062f7c0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=tf_goodreads_train, validation_data=tf_goodreads_val, epochs=3, callbacks=[model_checkpoint_callback, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89a301e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fecb0802b60>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(f\"./checkpoints/best_val_model_{model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0eec7f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560/560 [==============================] - 41s 74ms/step - loss: 0.4043 - accuracy: 0.8157 - balanced_sparse_categorical_accuracy: 0.8162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.40434446930885315, 0.8156808018684387, 0.8161695003509521]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(tf_goodreads_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e885b9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 560/560 [01:21<00:00,  6.84it/s]\n"
     ]
    }
   ],
   "source": [
    "auc = tf.keras.metrics.AUC()\n",
    "acc = tf.keras.metrics.Accuracy()\n",
    "\n",
    "fp = tf.keras.metrics.FalsePositives()\n",
    "fn = tf.keras.metrics.FalseNegatives()\n",
    "tp = tf.keras.metrics.TruePositives()\n",
    "tn = tf.keras.metrics.TrueNegatives()\n",
    "\n",
    "for batch_data, batch_labels in tqdm(tf_goodreads_test):\n",
    "    preds = tf.nn.softmax(model(batch_data)[0])[:,1]\n",
    "    auc.update_state(batch_labels, preds)\n",
    "    acc.update_state(batch_labels, preds>=0.5)\n",
    "    \n",
    "    fp.update_state(batch_labels, preds >= 0.5)\n",
    "    fn.update_state(batch_labels, preds >= 0.5)\n",
    "    tp.update_state(batch_labels, preds >= 0.5)\n",
    "    tn.update_state(batch_labels, preds >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fb84aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8993575, 0.815625)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc.result().numpy(), acc.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b893f6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1961.0, 7617.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp.result().numpy(), tp.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "775babcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1343.0, 6999.0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn.result().numpy(), tn.result().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62449658",
   "metadata": {},
   "source": [
    "# Whole Goodreads test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a4865c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1378033it [00:35, 39212.67it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4a670dd9b70425cb96e14c3c97b77c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1217 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "exclude_reviews = set(x[\"review_id\"] for x in chain(goodreads_train, goodreads_test))\n",
    "len(exclude_reviews)\n",
    "whole_goodreads_test = []\n",
    "file = f\"{DATA_PATH}/goodreads/goodreads_review_spoiler.json\"\n",
    "\n",
    "with open(file, \"r\") as f:\n",
    "    for line in tqdm(f):\n",
    "        as_json = json.loads(line)\n",
    "        if as_json[\"review_id\"] not in exclude_reviews:\n",
    "            whole_goodreads_test.append(as_json)\n",
    "tf_whole_goodreads_test = create_tf_dataset(whole_goodreads_test)\n",
    "del whole_goodreads_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9985c5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38022/38022 [52:21<00:00, 12.10it/s]\n"
     ]
    }
   ],
   "source": [
    "auc = tf.keras.metrics.AUC()\n",
    "acc = tf.keras.metrics.Accuracy()\n",
    "\n",
    "fp = tf.keras.metrics.FalsePositives()\n",
    "fn = tf.keras.metrics.FalseNegatives()\n",
    "tp = tf.keras.metrics.TruePositives()\n",
    "tn = tf.keras.metrics.TrueNegatives()\n",
    "\n",
    "for batch_data, batch_labels in tqdm(tf_whole_goodreads_test):\n",
    "    preds = tf.nn.softmax(model(batch_data)[0])[:,1]\n",
    "    auc.update_state(batch_labels, preds)\n",
    "    acc.update_state(batch_labels, preds>=0.5)\n",
    "    \n",
    "    fp.update_state(batch_labels, preds >= 0.5)\n",
    "    fn.update_state(batch_labels, preds >= 0.5)\n",
    "    tp.update_state(batch_labels, preds >= 0.5)\n",
    "    tn.update_state(batch_labels, preds >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70b01a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.89521176, 0.77776927)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc.result().numpy(), acc.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "081f3f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(268962.0, 7536.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp.result().numpy(), tp.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e386b0c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1427.0, 938779.0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn.result().numpy(), tn.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae8e7a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
