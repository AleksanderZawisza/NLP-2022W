{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb63a7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH=\"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c298ca5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "418a615f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7157887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(data):\n",
    "    return tokenizer(data[\"text\"], truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86ccecf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c1dfe37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99ccc5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-24 21:42:57.544449: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-24 21:42:58.227699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38419 MB memory:  -> device: 0, name: A100-SXM4-40GB, pci bus id: 0000:87:00.0, compute capability: 8.0\n",
      "2022-11-24 21:43:00.115230: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification\n",
    "\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name, classifier_dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91028738",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BalancedSparseCategoricalAccuracy(tf.keras.metrics.SparseCategoricalAccuracy):\n",
    "    def __init__(self, name='balanced_sparse_categorical_accuracy', dtype=None):\n",
    "        super().__init__(name, dtype=dtype)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_flat = y_true\n",
    "        if y_true.shape.ndims == y_pred.shape.ndims:\n",
    "            y_flat = tf.squeeze(y_flat, axis=[-1])\n",
    "        y_true_int = tf.cast(y_flat, tf.int32)\n",
    "\n",
    "        cls_counts = tf.math.bincount(y_true_int)\n",
    "        cls_counts = tf.math.reciprocal_no_nan(tf.cast(cls_counts, self.dtype))\n",
    "        weight = tf.gather(cls_counts, y_true_int)\n",
    "        return super().update_state(y_true, y_pred, sample_weight=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d000501",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_all_sentences(sentences):\n",
    "    all_sentences = []\n",
    "    for sentence in sentences:\n",
    "        all_sentences.append(sentence[1])\n",
    "    return \" \".join(all_sentences)\n",
    "def get_reviews_from_tropes(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        reviews = []\n",
    "        for line in f:\n",
    "            book = json.loads(line)\n",
    "            reviews.append({'text': get_all_sentences(book['sentences']), 'label': book['has_spoiler']})\n",
    "        return reviews\n",
    "\n",
    "def tropes_to_tf(tropes_list, model_name):\n",
    "    tokenized_tropes = Dataset.from_list(tropes_list).map(preprocess_function, batched=True)\n",
    "    return model_name.prepare_tf_dataset(\n",
    "        tokenized_tropes, shuffle=True, batch_size=32, collate_fn=data_collator\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d11c1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tropes_train = get_reviews_from_tropes(f'{DATA_PATH}/tvtropes_books/tvtropes_books-train.json')\n",
    "tropes_test = get_reviews_from_tropes(f'{DATA_PATH}/tvtropes_books/tvtropes_books-test.json')\n",
    "tropes_val = get_reviews_from_tropes(f'{DATA_PATH}/tvtropes_books/tvtropes_books-val.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "547ce26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34758aceccea4548b08ca7d283bd4ebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/274 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "101ee650c62d4470af73f71e23390ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70edd9a40584473c8427718d89f68723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf_tropes_train = tropes_to_tf(tropes_train, model)\n",
    "tf_tropes_val = tropes_to_tf(tropes_test, model)\n",
    "tf_tropes_test = tropes_to_tf(tropes_val, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "418e3422",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import create_optimizer\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "batches_per_epoch = len(tropes_train) // batch_size\n",
    "\n",
    "total_train_steps = int(batches_per_epoch * num_epochs)\n",
    "\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr=2e-5, num_warmup_steps=0, \n",
    "    num_train_steps=total_train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "03668ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = 213915\n",
    "pos = 59347\n",
    "total = neg + pos\n",
    "weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "\n",
    "class_weight = [weight_for_1, weight_for_0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c96d1b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer,\n",
    "             metrics=['accuracy', BalancedSparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02313d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"./checkpoints/best_val_model\",\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cefb2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e729deef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8358395d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "8539/8539 [==============================] - 3916s 457ms/step - loss: 0.3740 - accuracy: 0.8337 - balanced_sparse_categorical_accuracy: 0.6933 - val_loss: 0.3492 - val_accuracy: 0.8474 - val_balanced_sparse_categorical_accuracy: 0.7344\n",
      "Epoch 2/3\n",
      "8539/8539 [==============================] - 3895s 456ms/step - loss: 0.2783 - accuracy: 0.8810 - balanced_sparse_categorical_accuracy: 0.7976 - val_loss: 0.3635 - val_accuracy: 0.8489 - val_balanced_sparse_categorical_accuracy: 0.7417\n",
      "Epoch 3/3\n",
      " 752/8539 [=>............................] - ETA: 56:46 - loss: 0.1807 - accuracy: 0.9285 - balanced_sparse_categorical_accuracy: 0.8796"
     ]
    }
   ],
   "source": [
    "model.fit(x=tf_tropes_train, validation_data=tf_tropes_val, epochs=3, callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18926b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(tf_tropes_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b4420f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 211ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TFSequenceClassifierOutput(loss=None, logits=array([[ 0.29023138,  0.34916064],\n",
       "       [ 0.34931722,  0.30988342],\n",
       "       [ 0.29810795,  0.20926128],\n",
       "       [ 0.16940089,  0.10431242],\n",
       "       [ 0.30276096,  0.23780829],\n",
       "       [ 0.22682428,  0.25773048],\n",
       "       [ 0.42555362,  0.23762904],\n",
       "       [ 0.30690712,  0.2631874 ],\n",
       "       [ 0.20597264,  0.12430929],\n",
       "       [ 0.0904084 , -0.05847306],\n",
       "       [ 0.2188375 ,  0.10585496],\n",
       "       [ 0.40851647,  0.3299694 ],\n",
       "       [ 0.32778746,  0.2464583 ],\n",
       "       [ 0.33404464,  0.32148886],\n",
       "       [ 0.35756263,  0.14559889],\n",
       "       [ 0.26798752,  0.2514991 ],\n",
       "       [ 0.4475265 ,  0.37847757],\n",
       "       [ 0.29502618,  0.20877525],\n",
       "       [ 0.40949923,  0.2736877 ],\n",
       "       [ 0.278615  ,  0.46980965],\n",
       "       [ 0.17033055,  0.16642803],\n",
       "       [ 0.31911743,  0.157756  ],\n",
       "       [ 0.32622588,  0.16656825],\n",
       "       [ 0.30639672,  0.16873321],\n",
       "       [ 0.11122294,  0.0373375 ],\n",
       "       [ 0.38310233,  0.31911883],\n",
       "       [ 0.30635056,  0.290002  ],\n",
       "       [ 0.28456184,  0.20105536],\n",
       "       [ 0.32699925,  0.06944472],\n",
       "       [ 0.38211778,  0.3338974 ],\n",
       "       [ 0.40739053,  0.29077786],\n",
       "       [ 0.38666004,  0.27252895]], dtype=float32), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(tf_tropes_test.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b46004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./checkpoints/bert-base-uncased-3-epoch-dropout-01-tropes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf55b5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = tf.keras.metrics.AUC()\n",
    "acc = tf.keras.metrics.Accuracy()\n",
    "for batch_data, batch_labels in tqdm(tf_tropes_test):\n",
    "    preds = tf.nn.softmax(model(batch_data)[0])[:,1]\n",
    "    auc.update_state(batch_labels, preds)\n",
    "    acc.update_state(batch_labels, preds>=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "891f557c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84700096"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b54ca657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86697996"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1e253b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
