{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is meant to be run on Google Colab.\n",
    "\n",
    "In this notebook, we performed:\n",
    "\n",
    "* Demonstration of a probing task from [SentEval](https://github.com/facebookresearch/SentEval) - sentence_length\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environment set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lHdOMsFlarLu",
    "outputId": "1aa3892e-5ee5-4251-baec-586f59b36f48"
   },
   "outputs": [],
   "source": [
    "# !pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# git clone https://github.com/facebookresearch/SentEval.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Sa9_Q9tddNe",
    "outputId": "1459002d-7739-476c-de2b-67bf474b7d2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive/\n"
     ]
    }
   ],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive/', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h6kWzrlNd_E2"
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_SENTEVAL = '/content/SentEval/'\n",
    "\n",
    "sys.path.insert(0, PATH_TO_SENTEVAL)\n",
    "import senteval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from config import SENTEVAL_PROBING_PATH\n",
    "from source.probing.senteval_probing.sentence_length import create_sentence_length_probing_file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing probing input file\n",
    "\n",
    "Performing a probing task in SentEval requires preparing an input file first, e.g., for `sentence_length` probing task we need to prepare the `sentence_length.txt`.\n",
    "\n",
    "See more info at [SentEval repo](https://github.com/facebookresearch/SentEval/tree/main/data/probing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_sentence_length_probing_file(SENTEVAL_PROBING_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Prepare SentEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_senteval = {'task_path': SENTEVAL_PROBING_PATH, 'usepytorch': True, 'kfold': 2}\n",
    "params_senteval['classifier'] = {'nhid': 0, 'optim': 'rmsprop', 'batch_size': 16,\n",
    "                                 'tenacity': 3, 'epoch_size': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = '/content/drive/MyDrive/NLP/output/training_wdc_computers_medium_xlm-roberta-base-2022-12-27_18-12-53'\n",
    "\n",
    "\n",
    "# SentEval prepare and batcher\n",
    "def prepare(params, samples):\n",
    "    return\n",
    "\n",
    "def batcher(params, batch):\n",
    "    model_save_path = MODEL_PATH\n",
    "    model = SentenceTransformer(model_save_path)\n",
    "    batch_size = params.batch_size\n",
    "    embeddings = model.encode(batch, batch_size=batch_size, show_progress_bar=True, convert_to_numpy=True)\n",
    "    return embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Perform probing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se = senteval.engine.SE(params_senteval, batcher, prepare)\n",
    "transfer_tasks = ['Length'] # specify more probing tasks, but remember to create corresponding input files in the `SENTEVAL_PROBING_PATH`` dir\n",
    "results = se.eval(transfer_tasks)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 22:45:29) [MSC v.1916 32 bit (Intel)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e356dd047687aae92824e4bc0188a2818a6df554d25fe2bbe32ed0c4d26f6b28"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
