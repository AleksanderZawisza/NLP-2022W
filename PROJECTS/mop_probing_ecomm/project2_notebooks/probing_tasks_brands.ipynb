{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import importlib\n",
    "\n",
    "# setting path\n",
    "import os, sys\n",
    "current_dir = os.path.abspath('')\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from source.utils.probing_tasks_utils import *\n",
    "from source.load_data.wdc.load_wdc_dataset import EnglishDatasetLoader\n",
    "from source.utils.levenshtein_distance import compute_lev_dist_for_pairs\n",
    "from source.emb_extr_res.emb_extr_res import get_embeddings_df\n",
    "from source.utils.visualization import plot_histogram\n",
    "from source.probing.similarity_pairs_probing.get_data import get_pair_similarity_probing_task_df\n",
    "from config import TYPE, SIZE, EMBEDDING_PATH, DATA_PATH, MODEL_TYPE\n",
    "from source.emb_extr_res.emb_extr_res import get_embeddings_df, get_pairs_similarity_df, get_pretrain_agg_similarity\n",
    "from source.load_data.wdc.load_wdc_dataset import EnglishDatasetLoader\n",
    "from source.probing.brand_names import prepare_brands_list, brands_in_title_check, prepare_new_dataset, drop_brands\n",
    "from source.probing.length import prepare_probing_len\n",
    "from source.probing.words import words_in_title_check\n",
    "from source.probing.load_data import load_files_probing_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TYPE:\", TYPE)\n",
    "print(\"SIZE:\", SIZE)\n",
    "print(\"MODEL:\", MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all needed data\n",
    "\n",
    "test_embeddings_path, train_embeddings_path, embedding_train_df, train_df = load_files_probing_tasks(EMBEDDING_PATH, DATA_PATH, TYPE, SIZE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probing Task: Brands in Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare brands name list \n",
    "\n",
    "brands_to_drop_cameras = [',', 'd','memory',  'photo', 'co', 'usa',  'power',  'digital', 'camera', 'cam',  'hd',  'a',  'inc',  'le',  'film',  'case',  'pro', 'cameras']\n",
    "brands_to_drop_computers = ['transcend','null ,  seagate technology',  'null ,  lenovo', '150', 'mfr num cssd f120gblsb',  'corsair ,  null',  'null ,  apple', 'icy box', 'a data',  '216', 'mfr num dtse9g2 128gb',  '\"TP-Link\"@en-US',  '219',  'intel ,  null',  '1', 'n1', 'mfr num wds240g1g0b', '268', 'mfr num dtduo3c 32gb' , 'yli', 'g skill\", ', 'null ,  amazon', 'mfr num mz 75e1t0b eu', 'null ,  crucial technology', 'null ,  samsung',  'null ,  hp', 'mfr num mtfddak512tbn 1ar1zabyy']\n",
    "\n",
    "if TYPE == \"cameras\":\n",
    "    brands_to_drop = brands_to_drop_cameras\n",
    "elif TYPE == \"computers\":\n",
    "    brands_to_drop = brands_to_drop_computers\n",
    "\n",
    "# list with brand names\n",
    "brands = prepare_brands_list(train_df, brands_to_drop)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # prepare dataset with randomly removed brand names from titles\n",
    "# # dataset needs embeddings calulations - > Google Cloud\n",
    "\n",
    "# new_dataset_brands, ids_of_removed_brands_offers = prepare_new_dataset(train_df, brands)\n",
    "\n",
    "# new_dataset_brands_origin = new_dataset_brands[new_dataset_brands[\"changed\"] == True].drop(\"changed\", axis=1)\n",
    "\n",
    "# # save data to use after embeddings extraction\n",
    "\n",
    "# new_dataset_brands_origin.to_csv(os.path.join(DATA_PATH, f'dataset_brands_{TYPE}_{MODEL_TYPE}.csv'), index=False)\n",
    "\n",
    "# np.save(os.path.join(DATA_PATH, 'ids_of_removed_brands_offers.npy'),ids_of_removed_brands_offers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataframe for probing task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data to use after embeddings extraction\n",
    "\n",
    "new_dataset_brands_origin = pd.read_csv(os.path.join(DATA_PATH, f'dataset_brands_{TYPE}_{MODEL_TYPE}.csv'))\n",
    "ids_of_removed_brands_offers = np.load(os.path.join(DATA_PATH, 'ids_of_removed_brands_offers.npy'))\n",
    "\n",
    "# check brands in title\n",
    "\n",
    "brands_in_title_df = brands_in_title_check(new_dataset_brands_origin, brands)\n",
    "deleted_ids = brands_in_title_df[brands_in_title_df[\"brand_in_title\"]==True][\"id\"].values\n",
    "\n",
    "# load new embeddings - after brands removal\n",
    "\n",
    "new_embeddings_brands = get_embeddings_df(os.path.join(EMBEDDING_PATH, 'new_embeddings_brands.csv'))\n",
    "\n",
    "\n",
    "# prepare new dataframe with labels to train probing tasks\n",
    "\n",
    "emb_brands = embedding_train_df[~embedding_train_df[\"id\"].isin(ids_of_removed_brands_offers)] \n",
    "\n",
    "emb_removed_brands = new_embeddings_brands[new_embeddings_brands[\"id\"].isin(ids_of_removed_brands_offers)]\n",
    "df_probing_brands = pd.concat([emb_removed_brands, emb_brands])\n",
    "\n",
    "df_probing_brands[\"label\"] = df_probing_brands[\"id\"].isin(deleted_ids)\n",
    "df_probing_brands = df_probing_brands.drop([\"id\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe to train probing task - brands\n",
    "\n",
    "df_probing_brands.to_csv(os.path.join(EMBEDDING_PATH, 'probing', 'df_probing_brands.csv'), index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b90b5480b90dfd82255d68efb607ef96370ef33575f247c89a0b81cbaa1e7b55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
