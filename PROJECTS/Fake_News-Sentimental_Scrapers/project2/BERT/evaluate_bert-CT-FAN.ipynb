{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cb28079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b9c3683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aee29de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d83f037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0289cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4668654f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUR_DATASET = \"CT-FAN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf333c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dev = pd.read_csv(f'../data/{CUR_DATASET}/Task3_english_dev.csv')\n",
    "data_train = pd.read_csv(f'../data/{CUR_DATASET}/Task3_english_training.csv')\n",
    "\n",
    "test_dataset = pd.concat([data_train, data_dev])\n",
    "# test_dataset = pd.read_csv(f'../data/{CUR_DATASET}/English_data_test_release_with_rating.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9306c22",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>public_id</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>our rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a228e0e</td>\n",
       "      <td>Distracted driving causes more deaths in Canad...</td>\n",
       "      <td>You Can Be Fined $1,500 If Your Passenger Is U...</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30c605a1</td>\n",
       "      <td>Missouri politicians have made statements afte...</td>\n",
       "      <td>Missouri lawmakers condemn Las Vegas shooting</td>\n",
       "      <td>partially false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c3dea290</td>\n",
       "      <td>Home Alone 2: Lost in New York is full of viol...</td>\n",
       "      <td>CBC Cuts Donald Trump's 'Home Alone 2' Cameo O...</td>\n",
       "      <td>partially false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f14e8eb6</td>\n",
       "      <td>But things took a turn for the worse when riot...</td>\n",
       "      <td>Obama’s Daughters Caught on Camera Burning US ...</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>faf024d6</td>\n",
       "      <td>It’s no secret that Epstein and Schiff share a...</td>\n",
       "      <td>Leaked Visitor Logs Reveal Schiff’s 78 Visits ...</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  public_id                                               text  \\\n",
       "0  5a228e0e  Distracted driving causes more deaths in Canad...   \n",
       "1  30c605a1  Missouri politicians have made statements afte...   \n",
       "2  c3dea290  Home Alone 2: Lost in New York is full of viol...   \n",
       "3  f14e8eb6  But things took a turn for the worse when riot...   \n",
       "4  faf024d6  It’s no secret that Epstein and Schiff share a...   \n",
       "\n",
       "                                               title       our rating  \n",
       "0  You Can Be Fined $1,500 If Your Passenger Is U...            FALSE  \n",
       "1      Missouri lawmakers condemn Las Vegas shooting  partially false  \n",
       "2  CBC Cuts Donald Trump's 'Home Alone 2' Cameo O...  partially false  \n",
       "3  Obama’s Daughters Caught on Camera Burning US ...            FALSE  \n",
       "4  Leaked Visitor Logs Reveal Schiff’s 78 Visits ...            FALSE  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c6d5880",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.rename(columns={'our rating':'label'}, inplace=True)\n",
    "test_dataset['label'] = test_dataset['label'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f76d020",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset['label'] = test_dataset['label'].replace({\n",
    "    'false' : 0,\n",
    "    'partially false' : 1,\n",
    "    'true' : 2,\n",
    "    'other' : 3,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0bf39c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = test_dataset[\"label\"].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89acbb06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c67ebbb",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc89159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if_stopwords = True\n",
    "if_lemmatize = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fff70bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43f2a8f",
   "metadata": {},
   "source": [
    "### Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7feef98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_text_fn = {\n",
    "    \"no_punctuation\": lambda txt: re.sub(r'[^\\w\\s]',' ', txt),\n",
    "    \"no_special_symbols\": lambda txt: re.sub('[$,#,&]', '', txt),\n",
    "    # \"no_digits\": lambda txt: re.sub('\\d*', '', txt),\n",
    "    \"no_www\": lambda txt: re.sub('w{3}', '', txt),\n",
    "    \"no_urls\": lambda txt: re.sub('http\\S+', '', txt),\n",
    "    \"no_spaces\": lambda txt: re.sub('\\s+', ' ', txt),\n",
    "    \"no_single_chars\": lambda txt: re.sub(r'\\s+[a-zA-Z]\\s+', ' ', txt)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d3e4eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, pipeline = preprocessing_text_fn):\n",
    "    text = str(text)\n",
    "    for fn in pipeline.keys():\n",
    "        text = pipeline[fn](text)\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6f9444d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_dataset[\"title\"] = test_dataset[\"title\"].apply(preprocess_text)\n",
    "test_dataset[\"text\"] = test_dataset[\"text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38dcda0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if if_stopwords:\n",
    "    for dataset in [test_dataset]:\n",
    "        for col in [\"title\", \"text\"]:\n",
    "\n",
    "            dataset[col] = dataset[col].str.lower().str.replace(\"’\", \"'\")\n",
    "            dataset[col] = dataset[col].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7decfdd2",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "004fe8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/marneusz/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/marneusz/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "if if_lemmatize:\n",
    "    \n",
    "    import nltk\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('omw-1.4')\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    \n",
    "    wnl = WordNetLemmatizer()\n",
    "    \n",
    "    for dataset in [test_dataset]:\n",
    "        for col in [\"title\", \"text\"]:\n",
    "            dataset[col] = dataset[col].str.lower().str.replace(\"’\", \"'\")\n",
    "            dataset[col] = dataset[col].apply(lambda x: ' '.join([wnl.lemmatize(word) for word in word_tokenize(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9be414aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = (test_dataset[\"title\"] + \" \" + test_dataset[\"text\"]).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb40a4b6",
   "metadata": {},
   "source": [
    "# Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5e63013",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77a451bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marneusz/anaconda3/envs/nlp-transformers/lib/python3.11/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():    \n",
    "    device = torch.device('cuda')    \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db3065bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02f7e865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, precision_score, recall_score, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d97bee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1044b5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f\"bert_{CUR_DATASET}_regexp_stopwords_{if_stopwords}_lemmatization_{if_lemmatize}_multiclass\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1453ac90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    f\"./models/{model_name}/\"\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15dbe07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_utils import tokenize_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5095640d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 1264/1264 [00:04<00:00, 265.29it/s]\n"
     ]
    }
   ],
   "source": [
    "input_ids, attention_masks, labels = tokenize_map(test_text, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9da8e7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a25ac7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f1a46792ef0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "seed = 10\n",
    "transformers.set_seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39f11da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TensorDataset(input_ids, attention_masks, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "855f741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(\n",
    "            test_dataset, \n",
    "            sampler = SequentialSampler(test_dataset), \n",
    "            batch_size = batch_size \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a7c2e9",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f84f8325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    pred_flat = np.argmax(predictions, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    \n",
    "    return balanced_accuracy_score(labels_flat, pred_flat)\n",
    "\n",
    "def flat_f1_score(predictions, labels):\n",
    "    pred_flat = np.argmax(predictions, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    \n",
    "\n",
    "    return f1_score(labels_flat, pred_flat, zero_division=0, average=\"weighted\")\n",
    "\n",
    "def mae(predictions, labels):\n",
    "    pred_flat = np.argmax(predictions, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.mean(np.abs(pred_flat - labels_flat))\n",
    "\n",
    "def mse(predictions, labels):\n",
    "    pred_flat = np.argmax(predictions, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.mean((pred_flat - labels_flat) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9624fe2",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a5f6508a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e239a0cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|███████████████████████████▋                                                                            | 21/79 [00:12<00:32,  1.76it/s]/home/marneusz/anaconda3/envs/nlp-transformers/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2006: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      " 29%|██████████████████████████████▎                                                                         | 23/79 [00:14<00:31,  1.76it/s]/home/marneusz/anaconda3/envs/nlp-transformers/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2006: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      " 48%|██████████████████████████████████████████████████                                                      | 38/79 [00:22<00:23,  1.76it/s]/home/marneusz/anaconda3/envs/nlp-transformers/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2006: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      " 67%|█████████████████████████████████████████████████████████████████████▊                                  | 53/79 [00:31<00:14,  1.74it/s]/home/marneusz/anaconda3/envs/nlp-transformers/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2006: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      " 72%|███████████████████████████████████████████████████████████████████████████                             | 57/79 [00:33<00:12,  1.75it/s]/home/marneusz/anaconda3/envs/nlp-transformers/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2006: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      " 94%|█████████████████████████████████████████████████████████████████████████████████████████████████▍      | 74/79 [00:43<00:02,  1.75it/s]/home/marneusz/anaconda3/envs/nlp-transformers/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2006: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:46<00:00,  1.71it/s]\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "total_eval_accuracy = 0\n",
    "total_eval_loss = 0\n",
    "total_eval_f1 = 0\n",
    "total_eval_mae = 0\n",
    "total_eval_mse = 0\n",
    "nb_eval_steps = 0\n",
    "\n",
    "for batch in tqdm(test_dataloader):\n",
    "\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "\n",
    "    with torch.no_grad():        \n",
    "\n",
    "        loss = model(b_input_ids, \n",
    "                     token_type_ids=None, \n",
    "                     attention_mask=b_input_mask,\n",
    "                     labels=b_labels)[0]\n",
    "\n",
    "        logits = model(b_input_ids, \n",
    "                       token_type_ids=None, \n",
    "                       attention_mask=b_input_mask,\n",
    "                       labels=b_labels)[1]\n",
    "\n",
    "    # Accumulate the validation loss.\n",
    "\n",
    "    total_eval_loss += loss.item()\n",
    "\n",
    "    # Move logits and labels to CPU:\n",
    "\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    # Calculate the accuracy for this batch of test sentences, and accumulate it over all batches:\n",
    "\n",
    "    total_eval_accuracy += accuracy(logits, label_ids)\n",
    "    total_eval_f1 += flat_f1_score(logits, label_ids)\n",
    "    total_eval_mae += mae(logits, label_ids)\n",
    "    total_eval_mse += mse(logits, label_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e1115bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.83937\n",
      "  F1: 0.88907\n",
      "  MAE: 0.15348\n",
      "  MSE: 0.26899\n",
      "  Test Loss: 0.35574\n",
      "  Test took: 63.109795331954956\n"
     ]
    }
   ],
   "source": [
    "# Report the final accuracy for this validation run.\n",
    "\n",
    "avg_val_accuracy = total_eval_accuracy / len(test_dataloader)\n",
    "print('  Accuracy: {0:.5f}'.format(avg_val_accuracy))\n",
    "\n",
    "# Report the final f1 score for this validation run.\n",
    "\n",
    "avg_val_f1 = total_eval_f1 / len(test_dataloader)\n",
    "print('  F1: {0:.5f}'.format(avg_val_f1))\n",
    "\n",
    "avg_val_mae = total_eval_mae / len(test_dataloader)\n",
    "print('  MAE: {0:.5f}'.format(avg_val_mae))\n",
    "\n",
    "avg_val_mse = total_eval_mse / len(test_dataloader)\n",
    "print('  MSE: {0:.5f}'.format(avg_val_mse))\n",
    "\n",
    "# Calculate the average loss over all of the batches.\n",
    "\n",
    "avg_val_loss = total_eval_loss / len(test_dataloader)\n",
    "\n",
    "\n",
    "\n",
    "# Measure how long the validation run took:\n",
    "\n",
    "test_time = time.time() - t0\n",
    "\n",
    "print('  Test Loss: {0:.5f}'.format(avg_val_loss))\n",
    "print('  Test took: {:}'.format(test_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f9261a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp-transformers] *",
   "language": "python",
   "name": "conda-env-nlp-transformers-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
