{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cb28079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b9c3683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aee29de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d83f037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0289cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4668654f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUR_DATASET = \"LIAR-PLUS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf333c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv(f'../data/{CUR_DATASET}/test2.tsv', sep='\\t', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9306c22",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11972.json</td>\n",
       "      <td>true</td>\n",
       "      <td>Building a wall on the U.S.-Mexico border will...</td>\n",
       "      <td>immigration</td>\n",
       "      <td>rick-perry</td>\n",
       "      <td>Governor</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>42</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>Radio interview</td>\n",
       "      <td>Meantime, engineering experts agree the wall w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11685.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Wisconsin is on pace to double the number of l...</td>\n",
       "      <td>jobs</td>\n",
       "      <td>katrina-shankland</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>democrat</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a news conference</td>\n",
       "      <td>She cited layoff notices received by the state...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11096.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Says John McCain has done nothing to help the ...</td>\n",
       "      <td>military,veterans,voting-record</td>\n",
       "      <td>donald-trump</td>\n",
       "      <td>President-Elect</td>\n",
       "      <td>New York</td>\n",
       "      <td>republican</td>\n",
       "      <td>63</td>\n",
       "      <td>114</td>\n",
       "      <td>51</td>\n",
       "      <td>37</td>\n",
       "      <td>61</td>\n",
       "      <td>comments on ABC's This Week.</td>\n",
       "      <td>Trump said that McCain \"has done nothing to he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5209.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>Suzanne Bonamici supports a plan that will cut...</td>\n",
       "      <td>medicare,message-machine-2012,campaign-adverti...</td>\n",
       "      <td>rob-cornilles</td>\n",
       "      <td>consultant</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>republican</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a radio show</td>\n",
       "      <td>But spending still goes up. In addition, many ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9524.json</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>When asked by a reporter whether hes at the ce...</td>\n",
       "      <td>campaign-finance,legal-issues,campaign-adverti...</td>\n",
       "      <td>state-democratic-party-wisconsin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>democrat</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>a web video</td>\n",
       "      <td>Our rating A Democratic Party web video making...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0           1           2   \\\n",
       "0   0  11972.json        true   \n",
       "1   1  11685.json       false   \n",
       "2   2  11096.json       false   \n",
       "3   3   5209.json   half-true   \n",
       "4   4   9524.json  pants-fire   \n",
       "\n",
       "                                                  3   \\\n",
       "0  Building a wall on the U.S.-Mexico border will...   \n",
       "1  Wisconsin is on pace to double the number of l...   \n",
       "2  Says John McCain has done nothing to help the ...   \n",
       "3  Suzanne Bonamici supports a plan that will cut...   \n",
       "4  When asked by a reporter whether hes at the ce...   \n",
       "\n",
       "                                                  4   \\\n",
       "0                                        immigration   \n",
       "1                                               jobs   \n",
       "2                    military,veterans,voting-record   \n",
       "3  medicare,message-machine-2012,campaign-adverti...   \n",
       "4  campaign-finance,legal-issues,campaign-adverti...   \n",
       "\n",
       "                                 5                     6          7   \\\n",
       "0                        rick-perry              Governor      Texas   \n",
       "1                 katrina-shankland  State representative  Wisconsin   \n",
       "2                      donald-trump       President-Elect   New York   \n",
       "3                     rob-cornilles            consultant     Oregon   \n",
       "4  state-democratic-party-wisconsin                   NaN  Wisconsin   \n",
       "\n",
       "           8   9    10  11  12  13                            14  \\\n",
       "0  republican  30   30  42  23  18               Radio interview   \n",
       "1    democrat   2    1   0   0   0             a news conference   \n",
       "2  republican  63  114  51  37  61  comments on ABC's This Week.   \n",
       "3  republican   1    1   3   1   1                  a radio show   \n",
       "4    democrat   5    7   2   2   7                   a web video   \n",
       "\n",
       "                                                  15  \n",
       "0  Meantime, engineering experts agree the wall w...  \n",
       "1  She cited layoff notices received by the state...  \n",
       "2  Trump said that McCain \"has done nothing to he...  \n",
       "3  But spending still goes up. In addition, many ...  \n",
       "4  Our rating A Democratic Party web video making...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c6d5880",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_dataset.iloc[:, [2, 3, 15]]\n",
    "test = test.rename(columns = {2: 'label', 3: 'statements', 15: 'justification'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f76d020",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [test]:\n",
    "    dataset['label'] = dataset['label'].replace({\n",
    "        'false' : 0,\n",
    "        'barely-true' : 1,\n",
    "        'pants-fire' : 2,\n",
    "        'half-true' : 3,\n",
    "        'mostly-true' : 4,\n",
    "        'true' : 5\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0bf39c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [test]:\n",
    "    dataset = dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89acbb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = test[\"label\"].values.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c67ebbb",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc89159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if_stopwords = True\n",
    "if_lemmatize = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43f2a8f",
   "metadata": {},
   "source": [
    "### Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7feef98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_text_fn = {\n",
    "    \"no_punctuation\": lambda txt: re.sub(r'[^\\w\\s]',' ', txt),\n",
    "    \"no_special_symbols\": lambda txt: re.sub('[$,#,&]', '', txt),\n",
    "    # \"no_digits\": lambda txt: re.sub('\\d*', '', txt),\n",
    "    \"no_www\": lambda txt: re.sub('w{3}', '', txt),\n",
    "    \"no_urls\": lambda txt: re.sub('http\\S+', '', txt),\n",
    "    \"no_spaces\": lambda txt: re.sub('\\s+', ' ', txt),\n",
    "    \"no_single_chars\": lambda txt: re.sub(r'\\s+[a-zA-Z]\\s+', ' ', txt)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d3e4eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, pipeline = preprocessing_text_fn):\n",
    "    text = str(text)\n",
    "    for fn in pipeline.keys():\n",
    "        text = pipeline[fn](text)\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6f9444d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>statements</th>\n",
       "      <th>justification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Building wall on the S Mexico border will take...</td>\n",
       "      <td>Meantime engineering experts agree the wall wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Wisconsin is on pace to double the number of l...</td>\n",
       "      <td>She cited layoff notices received by the state...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Says John McCain has done nothing to help the ...</td>\n",
       "      <td>Trump said that McCain has done nothing to hel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Suzanne Bonamici supports plan that will cut c...</td>\n",
       "      <td>But spending still goes up In addition many ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>When asked by reporter whether hes at the cent...</td>\n",
       "      <td>Our rating Democratic Party web video making t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                         statements  \\\n",
       "0      5  Building wall on the S Mexico border will take...   \n",
       "1      0  Wisconsin is on pace to double the number of l...   \n",
       "2      0  Says John McCain has done nothing to help the ...   \n",
       "3      3  Suzanne Bonamici supports plan that will cut c...   \n",
       "4      2  When asked by reporter whether hes at the cent...   \n",
       "\n",
       "                                       justification  \n",
       "0  Meantime engineering experts agree the wall wo...  \n",
       "1  She cited layoff notices received by the state...  \n",
       "2  Trump said that McCain has done nothing to hel...  \n",
       "3  But spending still goes up In addition many ou...  \n",
       "4  Our rating Democratic Party web video making t...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dataset in [test]:\n",
    "    dataset[\"statements\"] = dataset[\"statements\"].apply(preprocess_text)\n",
    "    dataset[\"justification\"] = dataset[\"justification\"].apply(preprocess_text)\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38dcda0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "if if_stopwords:\n",
    "    for dataset in [test]:\n",
    "        for col in [\"statements\", \"justification\"]:\n",
    "            dataset[col] = dataset[col].str.lower().str.replace(\"’\", \"'\")\n",
    "            dataset[col] = dataset[col].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7decfdd2",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "004fe8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/marneusz/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/marneusz/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "if if_lemmatize:\n",
    "    \n",
    "    import nltk\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('omw-1.4')\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    \n",
    "    wnl = WordNetLemmatizer()\n",
    "    \n",
    "    for dataset in [test]:\n",
    "        for col in [\"statements\", \"justification\"]:\n",
    "            dataset[col] = dataset[col].str.lower().str.replace(\"’\", \"'\")\n",
    "            dataset[col] = dataset[col].apply(lambda x: ' '.join([wnl.lemmatize(word) for word in word_tokenize(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9be414aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = (test[\"statements\"] + \" \" + test[\"justification\"]).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb40a4b6",
   "metadata": {},
   "source": [
    "# Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a5e63013",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77a451bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marneusz/anaconda3/envs/nlp-transformers/lib/python3.11/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():    \n",
    "    device = torch.device('cuda')    \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db3065bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02f7e865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d97bee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1044b5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert_regexp_stopwords_lemmatization\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1453ac90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    f\"./models/{model_name}/\"\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15dbe07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_utils import tokenize_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5095640d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 44898/44898 [01:43<00:00, 433.65it/s]\n"
     ]
    }
   ],
   "source": [
    "input_ids, attention_masks, labels = tokenize_map(test_text, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9da8e7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a25ac7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f6fcd936f70>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "seed = 10\n",
    "transformers.set_seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39f11da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TensorDataset(input_ids, attention_masks, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "855f741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(\n",
    "            test_dataset, \n",
    "            sampler = SequentialSampler(test_dataset), \n",
    "            batch_size = batch_size \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a7c2e9",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f84f8325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    pred_flat = np.argmax(predictions, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    \n",
    "    return accuracy_score(labels_flat, pred_flat)\n",
    "\n",
    "def flat_f1_score(predictions, labels):\n",
    "    pred_flat = np.argmax(predictions, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    \n",
    "\n",
    "    return f1_score(labels_flat, pred_flat, zero_division=0)\n",
    "\n",
    "def mae(predictions, labels):\n",
    "    pred_flat = np.argmax(predictions, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.mean(np.abs(pred_flat - labels_flat))\n",
    "\n",
    "def mse(predictions, labels):\n",
    "    pred_flat = np.argmax(predictions, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.mean((pred_flat - labels_flat) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9624fe2",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a5f6508a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e239a0cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2807/2807 [26:44<00:00,  1.75it/s]\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "total_eval_accuracy = 0\n",
    "total_eval_loss = 0\n",
    "total_eval_f1 = 0\n",
    "total_eval_mae = 0\n",
    "total_eval_mse = 0\n",
    "nb_eval_steps = 0\n",
    "\n",
    "for batch in tqdm(test_dataloader):\n",
    "\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "\n",
    "    with torch.no_grad():        \n",
    "\n",
    "        loss = model(b_input_ids, \n",
    "                     token_type_ids=None, \n",
    "                     attention_mask=b_input_mask,\n",
    "                     labels=b_labels)[0]\n",
    "\n",
    "        logits = model(b_input_ids, \n",
    "                       token_type_ids=None, \n",
    "                       attention_mask=b_input_mask,\n",
    "                       labels=b_labels)[1]\n",
    "\n",
    "    # Accumulate the validation loss.\n",
    "\n",
    "    total_eval_loss += loss.item()\n",
    "\n",
    "    # Move logits and labels to CPU:\n",
    "\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    # Calculate the accuracy for this batch of test sentences, and accumulate it over all batches:\n",
    "\n",
    "    total_eval_accuracy += accuracy(logits, label_ids)\n",
    "    total_eval_f1 += flat_f1_score(logits, label_ids)\n",
    "    total_eval_mae += mae(logits, label_ids)\n",
    "    total_eval_mse += mse(logits, label_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e1115bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.41517\n",
      "  F1: 0.57178\n",
      "  Validation Loss: 5.92430\n",
      "  Validation took: 1604.4437456130981\n"
     ]
    }
   ],
   "source": [
    "# Report the final accuracy for this validation run.\n",
    "\n",
    "avg_val_accuracy = total_eval_accuracy / len(test_dataloader)\n",
    "print('  Accuracy: {0:.5f}'.format(avg_val_accuracy))\n",
    "\n",
    "# Report the final f1 score for this validation run.\n",
    "\n",
    "avg_val_f1 = total_eval_f1 / len(test_dataloader)\n",
    "print('  F1: {0:.5f}'.format(avg_val_f1))\n",
    "\n",
    "avg_val_mae = total_eval_mae / len(test_dataloader)\n",
    "print('  MAE: {0:.5f}'.format(avg_val_mae))\n",
    "\n",
    "avg_val_mse = total_eval_mse / len(test_dataloader)\n",
    "print('  MSE: {0:.5f}'.format(avg_val_mse))\n",
    "\n",
    "# Calculate the average loss over all of the batches.\n",
    "\n",
    "avg_val_loss = total_eval_loss / len(test_dataloader)\n",
    "\n",
    "\n",
    "\n",
    "# Measure how long the validation run took:\n",
    "\n",
    "test_time = time.time() - t0\n",
    "\n",
    "print('  Test Loss: {0:.5f}'.format(avg_val_loss))\n",
    "print('  Test took: {:}'.format(test_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp-transformers] *",
   "language": "python",
   "name": "conda-env-nlp-transformers-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
