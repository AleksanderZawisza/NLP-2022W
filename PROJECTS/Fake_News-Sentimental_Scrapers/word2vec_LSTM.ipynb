{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44d86d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from ast import literal_eval\n",
    "\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Embedding, Input, CuDNNLSTM, LSTM\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fda2fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"../data/ISOT_Preprocessed/data.csv\", index_col=0)\n",
    "dataset.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d555a623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['donald', 'trump', 'couldn', 'wish', 'america...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['house', 'intelligence', 'committee', 'chairm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['friday', 'reveal', 'milwaukee', 'sheriff', '...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['christmas', 'day', 'donald', 'trump', 'annou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['pope', 'francis', 'use', 'annual', 'christma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44893</th>\n",
       "      <td>['brussels', 'reuter', 'nato', 'ally', 'tuesda...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44894</th>\n",
       "      <td>['london', 'reuters', 'lexisnexi', 'provider',...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44895</th>\n",
       "      <td>['minsk', 'reuter', 'shadow', 'disuse', 'sovie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44896</th>\n",
       "      <td>['moscow', 'reuter', 'vatican', 'secretary', '...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44897</th>\n",
       "      <td>['jakarta', 'reuters', 'indonesia', 'buy', '11...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44898 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      ['donald', 'trump', 'couldn', 'wish', 'america...      0\n",
       "1      ['house', 'intelligence', 'committee', 'chairm...      0\n",
       "2      ['friday', 'reveal', 'milwaukee', 'sheriff', '...      0\n",
       "3      ['christmas', 'day', 'donald', 'trump', 'annou...      0\n",
       "4      ['pope', 'francis', 'use', 'annual', 'christma...      0\n",
       "...                                                  ...    ...\n",
       "44893  ['brussels', 'reuter', 'nato', 'ally', 'tuesda...      1\n",
       "44894  ['london', 'reuters', 'lexisnexi', 'provider',...      1\n",
       "44895  ['minsk', 'reuter', 'shadow', 'disuse', 'sovie...      1\n",
       "44896  ['moscow', 'reuter', 'vatican', 'secretary', '...      1\n",
       "44897  ['jakarta', 'reuters', 'indonesia', 'buy', '11...      1\n",
       "\n",
       "[44898 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a761074",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [donald, trump, couldn, wish, americans, happy...\n",
       "1        [house, intelligence, committee, chairman, dev...\n",
       "2        [friday, reveal, milwaukee, sheriff, david, cl...\n",
       "3        [christmas, day, donald, trump, announce, work...\n",
       "4        [pope, francis, use, annual, christmas, day, m...\n",
       "                               ...                        \n",
       "44893    [brussels, reuter, nato, ally, tuesday, welcom...\n",
       "44894    [london, reuters, lexisnexi, provider, legal, ...\n",
       "44895    [minsk, reuter, shadow, disuse, sovietera, fac...\n",
       "44896    [moscow, reuter, vatican, secretary, state, ca...\n",
       "44897    [jakarta, reuters, indonesia, buy, 11, sukhoi,...\n",
       "Name: text, Length: 44898, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = dataset['text'].apply(literal_eval)\n",
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd7d208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 1000\n",
    "lengths = np.array([len(x) for x in articles])\n",
    "dataset = dataset[lengths < max_length]\n",
    "articles = articles[lengths < max_length]\n",
    "dataset = dataset.reset_index(drop = True)\n",
    "articles = articles.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96a9aa39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "986"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_length = max(articles.apply(len))\n",
    "article_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ce58444",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_size = 100\n",
    "\n",
    "word_model = gensim.models.Word2Vec(articles, vector_size = vec_size, window = 5, workers = 12)\n",
    "word_model.train(articles, epochs = 10, total_examples = len(articles))\n",
    "wv = word_model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "471dcd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(articles)\n",
    "vocabulary_size = len(tokenizer.word_index) + 1\n",
    "encoded_articles = tokenizer.texts_to_sequences(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "563d89f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# To consider: avoid articles longer than x\n",
    "count = 0\n",
    "for i in range(0, len(encoded_articles)):\n",
    "    if len(encoded_articles[i]) > 1000:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "021b92f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_articles = pad_sequences(encoded_articles, maxlen = article_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1fe78c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44665, 986)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_articles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56192310",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_matrix = np.zeros(shape=(vocabulary_size, vec_size))\n",
    "for w, i in tokenizer.word_index.items():\n",
    "    ind = wv.has_index_for(w)\n",
    "    if ind:\n",
    "        emb_matrix[i] = wv.get_vector(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eef97466",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(padded_articles, dataset['label'], test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5b480ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.initializers import Constant\n",
    "from keras.layers import ReLU\n",
    "from keras.layers import Dropout\n",
    "model=Sequential()\n",
    "model.add(Embedding(input_dim = vocabulary_size, \n",
    "                    output_dim = vec_size,\n",
    "                    input_length = article_length,\n",
    "                    embeddings_initializer = Constant(emb_matrix))\n",
    "         )\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.20))\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(Dropout(0.10))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ff90ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 986, 100)          20719700  \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 986, 32)           17024     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 31552)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               4038784   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                2064      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,777,589\n",
      "Trainable params: 24,777,589\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebccd127",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=RMSprop(learning_rate=1e-5),loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5964325b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=20\n",
    "batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61bc96b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "262/262 [==============================] - 19s 69ms/step - loss: 0.4952 - accuracy: 0.8010 - val_loss: 0.3357 - val_accuracy: 0.8888\n",
      "Epoch 2/20\n",
      "262/262 [==============================] - 18s 69ms/step - loss: 0.2939 - accuracy: 0.8935 - val_loss: 0.2179 - val_accuracy: 0.9311\n",
      "Epoch 3/20\n",
      "262/262 [==============================] - 18s 67ms/step - loss: 0.2091 - accuracy: 0.9288 - val_loss: 0.1533 - val_accuracy: 0.9510\n",
      "Epoch 4/20\n",
      "262/262 [==============================] - 19s 73ms/step - loss: 0.1534 - accuracy: 0.9512 - val_loss: 0.1118 - val_accuracy: 0.9664\n",
      "Epoch 5/20\n",
      "262/262 [==============================] - 19s 73ms/step - loss: 0.1151 - accuracy: 0.9668 - val_loss: 0.0825 - val_accuracy: 0.9753\n",
      "Epoch 6/20\n",
      "262/262 [==============================] - 18s 68ms/step - loss: 0.0854 - accuracy: 0.9764 - val_loss: 0.0617 - val_accuracy: 0.9808\n",
      "Epoch 7/20\n",
      "262/262 [==============================] - 19s 72ms/step - loss: 0.0665 - accuracy: 0.9825 - val_loss: 0.0474 - val_accuracy: 0.9853\n",
      "Epoch 8/20\n",
      "262/262 [==============================] - 19s 71ms/step - loss: 0.0515 - accuracy: 0.9870 - val_loss: 0.0374 - val_accuracy: 0.9884\n",
      "Epoch 9/20\n",
      "262/262 [==============================] - 17s 66ms/step - loss: 0.0408 - accuracy: 0.9897 - val_loss: 0.0302 - val_accuracy: 0.9905\n",
      "Epoch 10/20\n",
      "262/262 [==============================] - 19s 73ms/step - loss: 0.0325 - accuracy: 0.9921 - val_loss: 0.0248 - val_accuracy: 0.9919\n",
      "Epoch 11/20\n",
      "262/262 [==============================] - 18s 67ms/step - loss: 0.0264 - accuracy: 0.9939 - val_loss: 0.0211 - val_accuracy: 0.9939\n",
      "Epoch 12/20\n",
      "262/262 [==============================] - 16s 60ms/step - loss: 0.0215 - accuracy: 0.9956 - val_loss: 0.0181 - val_accuracy: 0.9954\n",
      "Epoch 13/20\n",
      "262/262 [==============================] - 18s 70ms/step - loss: 0.0182 - accuracy: 0.9960 - val_loss: 0.0157 - val_accuracy: 0.9958\n",
      "Epoch 14/20\n",
      "262/262 [==============================] - 16s 62ms/step - loss: 0.0142 - accuracy: 0.9970 - val_loss: 0.0142 - val_accuracy: 0.9961\n",
      "Epoch 15/20\n",
      "262/262 [==============================] - 16s 61ms/step - loss: 0.0124 - accuracy: 0.9976 - val_loss: 0.0128 - val_accuracy: 0.9964\n",
      "Epoch 16/20\n",
      "262/262 [==============================] - 16s 63ms/step - loss: 0.0105 - accuracy: 0.9979 - val_loss: 0.0119 - val_accuracy: 0.9966\n",
      "Epoch 17/20\n",
      "262/262 [==============================] - 16s 62ms/step - loss: 0.0090 - accuracy: 0.9981 - val_loss: 0.0111 - val_accuracy: 0.9966\n",
      "Epoch 18/20\n",
      "262/262 [==============================] - 15s 57ms/step - loss: 0.0077 - accuracy: 0.9986 - val_loss: 0.0106 - val_accuracy: 0.9969\n",
      "Epoch 19/20\n",
      "262/262 [==============================] - 14s 54ms/step - loss: 0.0065 - accuracy: 0.9987 - val_loss: 0.0113 - val_accuracy: 0.9967\n",
      "Epoch 20/20\n",
      "262/262 [==============================] - 14s 54ms/step - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.0099 - val_accuracy: 0.9971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22600c0ba90>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a916ae1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
