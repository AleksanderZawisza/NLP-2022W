\section{Project proposal reviews discussion}

\subsection{Strong points analysis}
We would like to shortly summarise a few aspects which were positively viewed. Reviewers seemed to be satisfied with our choice of the datasets, they found them e.g. "interesting". They were also interested in seeing various experiments  that are planned and their results. Our overall score was 4.25 out of 5 which lands somewhere between "Strong" and "Exciting". This ensures us that goal of our project is worth pursuing and as a team, we are on a good track. 

\subsection{Weak points analysis}
Whereas positive opinions bring some amount of satisfaction, one of the key purposes of every review is to find weak points in the work. They may cast a light on committed mistakes or wrong assumptions. We received a fair share of criticism, nevertheless, in our opinion, the process that we presented is still valid, yet it might benefit from a few changes. It was pointed out to us that we should justify the novelty of our work slightly better. One reviewer raised a concern that our classification models might be too simple, and in some cases this might be true, but we do not expect great performance from them all. This work is oriented on the comparison of different approaches and in our opinion it will be highly beneficial to see by how much e.g. Naive Bayes performs worse than CNN. Additionally, we received a couple of comments about the presentation itself, which are irrelevant going further in the project. Overall we are satisfied with the criticism we received, mainly due to the fact that reviewers pointed out several possible improvements and they did not spot any critical mistakes or flaws in our understanding of the matter. This leaves us ensured that the project can be continued without the necessity for any major changes and the obtained results will be valuable to other scholars.  