{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from config import EMBEDDING_PATH\n",
    "from emb_extr_res.emb_extr_res import get_embeddings_df\n",
    "from load_data.wdc.load_wdc_dataset import EnglishDatasetLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = \"cameras\"\n",
    "dataset_size = \"medium\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "train_df = EnglishDatasetLoader.load_train(dataset_type, dataset_size)\n",
    "test_df = EnglishDatasetLoader.load_test(dataset_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ids_and_cluster_ids(train_df):\n",
    "    \"\"\"\n",
    "    extract unique pairs of cluster_id and offer_id\n",
    "    \"\"\"\n",
    "    train_df_left = train_df[[\"id_left\", \"cluster_id_left\"]]\n",
    "    train_df_right = train_df[[\"id_right\", \"cluster_id_right\"]]\n",
    "    train_df_left = train_df_left.drop_duplicates().rename({\"id_left\" : \"offer_id\", \"cluster_id_left\" : \"product_id\"}, axis = 'columns')\n",
    "    train_df_right = train_df_right.drop_duplicates().rename({\"id_right\" : \"offer_id\", \"cluster_id_right\" : \"product_id\"}, axis = 'columns')\n",
    "    df_train_all = pd.concat([train_df_right, train_df_left])\n",
    "\n",
    "    return df_train_all.drop_duplicates()\n",
    "\n",
    "\n",
    "def extract_most_common_ids(train_df, how_many=5):\n",
    "    \"\"\"\n",
    "    Take products ids that occurs in most offers .\n",
    "    Returns: pairs of offer_id and product_id.\n",
    "    \"\"\"\n",
    "\n",
    "    id_title = extract_ids_and_cluster_ids(train_df)\n",
    "    clusters, count = np.unique(id_title[\"product_id\"], return_counts=True)\n",
    "\n",
    "    clusters_count = []\n",
    "\n",
    "    for i in range(len(clusters)):\n",
    "        clusters_count.append((clusters[i], count[i]))\n",
    "\n",
    "    clusters_count.sort(key = lambda x: x[1], reverse=True)\n",
    "\n",
    "    return id_title[id_title[\"product_id\"].isin( [tup[0] for tup in clusters_count[:how_many]])]\n",
    "\n",
    "def get_dataset_with_labels(dataset, embeddings):\n",
    "    most_common_ids = extract_most_common_ids(dataset)\n",
    "\n",
    "    features = embeddings[embeddings[\"id\"].isin(most_common_ids[\"offer_id\"])]\n",
    "\n",
    "    new_dataset = pd.merge(features, most_common_ids,left_on = \"id\", right_on = \"offer_id\",  how='left').drop([\"id\"], axis=1).rename({\"product_id\":\"label\"}, axis = 'columns')\n",
    "\n",
    "    return new_dataset, most_common_ids\n",
    "\n",
    "def get_test_dataset(test_df, test_embeddings, train_ids):\n",
    "    res = extract_ids_and_cluster_ids(test_df)\n",
    "    ids_needed = res[res[\"product_id\"].isin(train_ids[\"product_id\"])]\n",
    "    features = test_embeddings[test_embeddings[\"id\"].isin(ids_needed[\"offer_id\"])]\n",
    "\n",
    "    return pd.merge(features, res,left_on = \"id\", right_on = \"offer_id\",  how='left').drop([\"id\"], axis=1).rename({\"product_id\":\"label\"}, axis = 'columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings_path = path.join(EMBEDDING_PATH, r'train_embeddings.csv')\n",
    "train_embeddings = get_embeddings_df(train_embeddings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cluster_id_dataset, ids = get_dataset_with_labels(train_df, train_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings_path = path.join(EMBEDDING_PATH, r'test_embeddings.csv')\n",
    "test_embeddings = get_embeddings_df(test_embeddings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cluster_id_dataset = get_test_dataset(test_df, test_embeddings, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.probing_tasks_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0, f_score: 1.0\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "pred_rf, acc_rf, f_score_rf = test_probing_task(train_cluster_id_dataset, test_cluster_id_dataset, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.16666666666666666, f_score: 0.05714285714285714\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(\n",
    "        multi_class=\"multinomial\", random_state=42, penalty=\"l1\", solver=\"saga\"\n",
    "    )\n",
    "pred_lr, acc_lr, f_score_lr = test_probing_task(train_cluster_id_dataset, test_cluster_id_dataset, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0, f_score: 1.0\n"
     ]
    }
   ],
   "source": [
    "clf = XGBClassifier()\n",
    "pred_lr, acc_lr, f_score_lr = test_probing_task(train_cluster_id_dataset, test_cluster_id_dataset, clf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c536d464c425baa195bec6e8a0508c63c0f4224f917fb0d5c1fc3d571634ac5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
