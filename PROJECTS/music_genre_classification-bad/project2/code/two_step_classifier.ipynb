{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import absl.logging\n",
    "from nlp_embedding import GloVe, SmallBert, Bert, Word2vec, LargeBert\n",
    "from nlp_classifier import NaiveBayes, SVM, XGBoost, CNN, BinaryCNN\n",
    "from sklearn import preprocessing, metrics\n",
    "from ast import literal_eval\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 400\n",
    "dataset_name = 'small'\n",
    "cnn_epochs = 5\n",
    "indiv_genre = 'Rock'\n",
    "optimizer = 'adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "class CNN2Step():\n",
    "    def __init__(self, vec_len, class_count, optimizer, indiv_class):\n",
    "        self.name = '2_step_cnn'\n",
    "        self.model1 = BinaryCNN(vec_len, optimizer)\n",
    "        self.model2 = CNN(vec_len, class_count - 1, optimizer)\n",
    "        self.indiv_class = indiv_class\n",
    "\n",
    "    def partial_fit(self, X, Y):\n",
    "        Y_binary = np.array(Y == self.indiv_class).astype(int)\n",
    "        self.model1.partial_fit(X.reshape(*X.shape, 1), Y_binary.reshape(-1, 1))\n",
    "        \n",
    "        X_other = X[Y != self.indiv_class]\n",
    "        Y_other = Y[Y != self.indiv_class]\n",
    "        self.model2.partial_fit(X_other.reshape(*X_other.shape, 1), Y_other.reshape(-1, 1))\n",
    "\n",
    "    def predict(self, X):\n",
    "        pred1 = self.model1.predict(X.reshape(*X.shape, 1))\n",
    "        X2 = X[pred1 == 0]\n",
    "        pred2 = self.model2.predict(X2.reshape(*X2.shape, 1))\n",
    "        \n",
    "        pred = np.zeros(len(X), dtype=int)\n",
    "        pred[pred1 == 1] = self.indiv_class\n",
    "        pred[pred1 == 0] = pred2\n",
    "\n",
    "        print(np.unique(pred))\n",
    "        print(np.unique(pred1))\n",
    "        print(np.unique(pred2))\n",
    "        \n",
    "        return pred.flatten()\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # we are not using it anyway for now\n",
    "        pass\n",
    "    \n",
    "    def save(self, filename):\n",
    "        self.model1.save(f'{filename}1')\n",
    "        self.model2.save(f'{filename}2')\n",
    "\n",
    "    def load(self, filename):\n",
    "        self.model1 = models.load_model(f'{filename}1')\n",
    "        self.model2 = models.load_model(f'{filename}2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_x, data_y, nlp_embedding, nlp_classifier, label_encoder, batch_size, dataset_name, epochs=1, model_dir='models', start_idx=0, fname_end=''):\n",
    "    print('Training...')\n",
    "    fname = os.path.join(model_dir, dataset_name, f'model_{nlp_embedding.name}_{nlp_classifier.name}{fname_end}')\n",
    "    data_y_enc = label_encoder.transform(data_y)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f'Epoch: {str(epoch + 1)}/{str(epochs)}')\n",
    "        for i in range(start_idx, data_x.shape[0], batch_size):\n",
    "            \n",
    "            if i + batch_size > data_x.shape[0]:\n",
    "                j = data_x.shape[0]\n",
    "            else:\n",
    "                j = i + batch_size\n",
    "            \n",
    "            print(f'Processing rows: {i} - {j - 1}')\n",
    "\n",
    "            embeddings = nlp_embedding.embed_lyrics(data_x[i:j])\n",
    "            nlp_classifier.partial_fit(embeddings, data_y_enc[i:j])\n",
    "            nlp_classifier.save(fname)\n",
    "        start_idx = 0\n",
    "    \n",
    "    print('Success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(data_x, nlp_embedding, nlp_classifier, label_encoder, batch_size, dataset_name, pred_dir='predictions', start_idx=0, fname_end=''):\n",
    "    print('Testing...')\n",
    "    fname = os.path.join(pred_dir, dataset_name, f'model_{nlp_embedding.name}_{nlp_classifier.name}{fname_end}.csv')\n",
    "    predictions_all = []\n",
    "\n",
    "    if start_idx == 0 and os.path.exists(fname):\n",
    "        os.remove(fname)\n",
    "    \n",
    "    for i in range(start_idx, data_x.shape[0], batch_size):\n",
    "\n",
    "        if i + batch_size > data_x.shape[0]:\n",
    "            j = data_x.shape[0]\n",
    "        else:\n",
    "            j = i + batch_size\n",
    "        \n",
    "        print(f'Processing rows: {i} - {j - 1}')\n",
    "\n",
    "        embeddings = nlp_embedding.embed_lyrics(data_x[i:j])\n",
    "        predictions_enc = nlp_classifier.predict(embeddings)\n",
    "        predictions = label_encoder.inverse_transform(predictions_enc)\n",
    "        \n",
    "        predictions_all.extend(predictions)\n",
    "\n",
    "        pd.DataFrame(predictions.reshape(-1, 1)).to_csv(fname, mode='a', index=False, header=False)\n",
    "    \n",
    "    print('Success!')    \n",
    "    \n",
    "    return predictions_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(y_true, y_pred):\n",
    "    print('RESULTS:')\n",
    "    print(f'accuracy = {metrics.accuracy_score(y_true=y_true, y_pred=y_pred)}')\n",
    "    print(f'balanced accuracy = {metrics.balanced_accuracy_score(y_true=y_true, y_pred=y_pred)}')\n",
    "    print(f'f1 score = {metrics.f1_score(y_true=y_true, y_pred=y_pred, average=\"weighted\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_results(emb, clf, x_train, y_train, x_test, y_test, dataset_name, le, batch_size=5000, epochs=1, fname_end=''):\n",
    "    train(x_train, y_train, emb, clf, le, batch_size, dataset_name, epochs=epochs, fname_end=fname_end)\n",
    "    y_pred = test(x_test, emb, clf, le, batch_size, dataset_name, fname_end=fname_end)\n",
    "    get_results(y_test, y_pred)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_normalized_lyrics(data):\n",
    "    tokens = data.tokens.apply(literal_eval)\n",
    "    data['normalized_lyrics'] = [' '.join(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.path.join('models', dataset_name)\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "pred_dir = os.path.join('predictions', dataset_name)\n",
    "if not os.path.exists(pred_dir):\n",
    "    os.makedirs(pred_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(f'data/train/{dataset_name}.csv')\n",
    "test_data = pd.read_csv(f'data/test/{dataset_name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rock       87661\n",
       "Pop        33527\n",
       "Metal      24294\n",
       "Hip-Hop    21746\n",
       "Country    16257\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.genre.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rock       37569\n",
       "Pop        14369\n",
       "Metal      10412\n",
       "Hip-Hop     9320\n",
       "Country     6967\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.genre.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_normalized_lyrics(train_data)\n",
    "add_normalized_lyrics(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Country', 'Hip-Hop', 'Metal', 'Pop', 'Rock'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres = np.unique(train_data.genre)\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "label_encoder.fit(genres)\n",
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "indiv_genre_label = label_encoder.transform([indiv_genre])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smaller BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_sm_bert = SmallBert(max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_cnn = CNN(max_words * emb_sm_bert.embedding_size, len(genres), optimizer)\n",
    "train_and_save_results(emb_sm_bert, clf_cnn_norm,\n",
    "                       train_data.lyrics, train_data.genre, test_data.normalized_lyrics, test_data.genre, \n",
    "                       dataset_name, label_encoder, epochs=cnn_epochs, fname_end='_norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_cnn_norm = CNN(max_words * emb_sm_bert.embedding_size, len(genres), optimizer)\n",
    "train_and_save_results(emb_sm_bert, clf_cnn_norm,\n",
    "                       train_data.normalized_lyrics, train_data.genre, test_data.normalized_lyrics, test_data.genre, \n",
    "                       dataset_name, label_encoder, epochs=cnn_epochs, fname_end='_norm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_bert = Bert(max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_cnn_b = CNN(max_words * emb_bert.embedding_size, len(genres), optimizer)\n",
    "train_and_save_results(emb_bert, clf_cnn_b,\n",
    "                       train_data.lyrics, train_data.genre, test_data.lyrics, test_data.genre, \n",
    "                       dataset_name, label_encoder, epochs=cnn_epochs, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_cnn_b_norm = CNN(max_words * emb_bert.embedding_size, len(genres), optimizer)\n",
    "train_and_save_results(emb_bert, clf_cnn_b_norm,\n",
    "                       train_data.normalized_lyrics, train_data.genre, test_data.normalized_lyrics, test_data.genre, \n",
    "                       dataset_name, label_encoder, epochs=cnn_epochs, batch_size=1000, fname_end='_norm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_lr_bert = LargeBert(max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_cnn_bl = CNN(max_words * emb_lr_bert.embedding_size, len(genres), optimizer)\n",
    "train_and_save_results(emb_lr_bert, clf_cnn_bl,\n",
    "                       train_data.lyrics, train_data.genre, test_data.lyrics, test_data.genre, \n",
    "                       dataset_name, label_encoder, epochs=cnn_epochs, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_cnn_bl_norm = CNN(max_words * emb_lr_bert.embedding_size, len(genres), optimizer)\n",
    "train_and_save_results(emb_lr_bert, clf_cnn_bl_norm,\n",
    "                       train_data.normalized_lyrics, train_data.genre, test_data.normalized_lyrics, test_data.genre, \n",
    "                       dataset_name, label_encoder, epochs=cnn_epochs, batch_size=1000, fname_end='_norm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove_100d download started this may take some time.\n",
      "Approximate size to download 145.3 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "emb_glove = GloVe(max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_cnn_g = CNN(max_words * emb_glove.embedding_size, len(genres), optimizer)\n",
    "train_and_save_results(emb_glove, clf_cnn_g, \n",
    "                       train_data.lyrics, train_data.genre, test_data.lyrics, test_data.genre, \n",
    "                       dataset_name, label_encoder, epochs=cnn_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_cnn_g_norm = CNN(max_words * emb_glove.embedding_size, len(genres), optimizer)\n",
    "train_and_save_results(emb_glove, clf_cnn_g_norm, \n",
    "                       train_data.normalized_lyrics, train_data.genre, test_data.normalized_lyrics, test_data.genre, \n",
    "                       dataset_name, label_encoder, epochs=cnn_epochs, fname_end='_norm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-step CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch: 1/5\n",
      "Processing rows: 0 - 4999\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.7442 - accuracy: 0.5772\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 1.5695 - accuracy: 0.5168\n",
      "Processing rows: 5000 - 9999\n",
      "157/157 [==============================] - 27s 173ms/step - loss: 0.6487 - accuracy: 0.5924\n",
      "82/82 [==============================] - 22s 271ms/step - loss: 1.0263 - accuracy: 0.5654\n",
      "Processing rows: 10000 - 14999\n",
      "157/157 [==============================] - 28s 181ms/step - loss: 0.6489 - accuracy: 0.5928\n",
      "83/83 [==============================] - 23s 277ms/step - loss: 0.9669 - accuracy: 0.6054\n",
      "Processing rows: 15000 - 19999\n",
      "157/157 [==============================] - 29s 182ms/step - loss: 0.6377 - accuracy: 0.6004\n",
      "83/83 [==============================] - 25s 296ms/step - loss: 0.9385 - accuracy: 0.6241\n",
      "Processing rows: 20000 - 24999\n",
      "157/157 [==============================] - 27s 169ms/step - loss: 0.6479 - accuracy: 0.5958\n",
      "82/82 [==============================] - 22s 269ms/step - loss: 0.8974 - accuracy: 0.6290\n",
      "Processing rows: 25000 - 29999\n",
      "157/157 [==============================] - 27s 170ms/step - loss: 0.6371 - accuracy: 0.6054\n",
      "81/81 [==============================] - 20s 250ms/step - loss: 0.8710 - accuracy: 0.6381\n",
      "Processing rows: 30000 - 34999\n",
      "157/157 [==============================] - 27s 169ms/step - loss: 0.6431 - accuracy: 0.6050\n",
      "83/83 [==============================] - 21s 252ms/step - loss: 0.8583 - accuracy: 0.6579\n",
      "Processing rows: 35000 - 39999\n",
      "157/157 [==============================] - 27s 170ms/step - loss: 0.6325 - accuracy: 0.6222\n",
      "83/83 [==============================] - 22s 265ms/step - loss: 0.8441 - accuracy: 0.6438\n",
      "Processing rows: 40000 - 44999\n",
      "157/157 [==============================] - 27s 170ms/step - loss: 0.6384 - accuracy: 0.6146\n",
      "84/84 [==============================] - 23s 272ms/step - loss: 0.8495 - accuracy: 0.6550\n",
      "Processing rows: 45000 - 49999\n",
      "157/157 [==============================] - 27s 171ms/step - loss: 0.6347 - accuracy: 0.6180\n",
      "82/82 [==============================] - 22s 273ms/step - loss: 0.8240 - accuracy: 0.6598\n",
      "Processing rows: 50000 - 54999\n",
      "157/157 [==============================] - 27s 171ms/step - loss: 0.6321 - accuracy: 0.6208\n",
      "83/83 [==============================] - 23s 272ms/step - loss: 0.8168 - accuracy: 0.6683\n",
      "Processing rows: 55000 - 59999\n",
      "157/157 [==============================] - 27s 170ms/step - loss: 0.6347 - accuracy: 0.6254\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.8344 - accuracy: 0.6647\n",
      "Processing rows: 60000 - 64999\n",
      "157/157 [==============================] - 27s 170ms/step - loss: 0.6242 - accuracy: 0.6304\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.8160 - accuracy: 0.6587\n",
      "Processing rows: 65000 - 69999\n",
      "157/157 [==============================] - 27s 171ms/step - loss: 0.6297 - accuracy: 0.6338\n",
      "84/84 [==============================] - 23s 271ms/step - loss: 0.8257 - accuracy: 0.6644\n",
      "Processing rows: 70000 - 74999\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.6281 - accuracy: 0.6354\n",
      "81/81 [==============================] - 21s 256ms/step - loss: 0.8256 - accuracy: 0.6598\n",
      "Processing rows: 75000 - 79999\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.6232 - accuracy: 0.6332\n",
      "84/84 [==============================] - 23s 274ms/step - loss: 0.7731 - accuracy: 0.6834\n",
      "Processing rows: 80000 - 84999\n",
      "157/157 [==============================] - 27s 173ms/step - loss: 0.6276 - accuracy: 0.6240\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.7613 - accuracy: 0.6921\n",
      "Processing rows: 85000 - 89999\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.6296 - accuracy: 0.6246\n",
      "81/81 [==============================] - 22s 277ms/step - loss: 0.7972 - accuracy: 0.6757\n",
      "Processing rows: 90000 - 94999\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.6268 - accuracy: 0.6308\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.8236 - accuracy: 0.6606\n",
      "Processing rows: 95000 - 99999\n",
      "157/157 [==============================] - 27s 174ms/step - loss: 0.6236 - accuracy: 0.6350\n",
      "82/82 [==============================] - 23s 281ms/step - loss: 0.7803 - accuracy: 0.6734\n",
      "Processing rows: 100000 - 104999\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.6248 - accuracy: 0.6390\n",
      "81/81 [==============================] - 23s 280ms/step - loss: 0.7925 - accuracy: 0.6837\n",
      "Processing rows: 105000 - 109999\n",
      "157/157 [==============================] - 26s 165ms/step - loss: 0.6209 - accuracy: 0.6426\n",
      "83/83 [==============================] - 23s 280ms/step - loss: 0.7968 - accuracy: 0.6874\n",
      "Processing rows: 110000 - 114999\n",
      "157/157 [==============================] - 27s 171ms/step - loss: 0.6144 - accuracy: 0.6400\n",
      "79/79 [==============================] - 22s 275ms/step - loss: 0.7752 - accuracy: 0.6937\n",
      "Processing rows: 115000 - 119999\n",
      "157/157 [==============================] - 25s 161ms/step - loss: 0.6201 - accuracy: 0.6296\n",
      "83/83 [==============================] - 21s 251ms/step - loss: 0.7988 - accuracy: 0.6751\n",
      "Processing rows: 120000 - 124999\n",
      "157/157 [==============================] - 26s 168ms/step - loss: 0.6200 - accuracy: 0.6416\n",
      "82/82 [==============================] - 22s 268ms/step - loss: 0.7546 - accuracy: 0.6999\n",
      "Processing rows: 125000 - 129999\n",
      "157/157 [==============================] - 27s 171ms/step - loss: 0.6152 - accuracy: 0.6432\n",
      "84/84 [==============================] - 23s 276ms/step - loss: 0.7668 - accuracy: 0.6899\n",
      "Processing rows: 130000 - 134999\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.6095 - accuracy: 0.6524\n",
      "82/82 [==============================] - 23s 281ms/step - loss: 0.7598 - accuracy: 0.6851\n",
      "Processing rows: 135000 - 139999\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.6131 - accuracy: 0.6552\n",
      "82/82 [==============================] - 23s 280ms/step - loss: 0.7550 - accuracy: 0.6855\n",
      "Processing rows: 140000 - 144999\n",
      "157/157 [==============================] - 26s 168ms/step - loss: 0.6106 - accuracy: 0.6590\n",
      "82/82 [==============================] - 23s 281ms/step - loss: 0.7597 - accuracy: 0.6951\n",
      "Processing rows: 145000 - 149999\n",
      "157/157 [==============================] - 27s 175ms/step - loss: 0.6102 - accuracy: 0.6398\n",
      "83/83 [==============================] - 22s 262ms/step - loss: 0.7419 - accuracy: 0.7008\n",
      "Processing rows: 150000 - 154999\n",
      "157/157 [==============================] - 25s 160ms/step - loss: 0.6179 - accuracy: 0.6474\n",
      "82/82 [==============================] - 22s 266ms/step - loss: 0.7531 - accuracy: 0.7000\n",
      "Processing rows: 155000 - 159999\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.6126 - accuracy: 0.6456\n",
      "79/79 [==============================] - 22s 277ms/step - loss: 0.7530 - accuracy: 0.6950\n",
      "Processing rows: 160000 - 164999\n",
      "157/157 [==============================] - 25s 157ms/step - loss: 0.6079 - accuracy: 0.6480\n",
      "83/83 [==============================] - 23s 276ms/step - loss: 0.7564 - accuracy: 0.6963\n",
      "Processing rows: 165000 - 169999\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.6094 - accuracy: 0.6532\n",
      "82/82 [==============================] - 22s 274ms/step - loss: 0.7625 - accuracy: 0.6965\n",
      "Processing rows: 170000 - 174999\n",
      "157/157 [==============================] - 25s 159ms/step - loss: 0.6024 - accuracy: 0.6544\n",
      "83/83 [==============================] - 23s 275ms/step - loss: 0.7559 - accuracy: 0.6995\n",
      "Processing rows: 175000 - 179999\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.6077 - accuracy: 0.6518\n",
      "83/83 [==============================] - 23s 279ms/step - loss: 0.7594 - accuracy: 0.7019\n",
      "Processing rows: 180000 - 183484\n",
      "109/109 [==============================] - 18s 162ms/step - loss: 0.6161 - accuracy: 0.6416\n",
      "57/57 [==============================] - 16s 278ms/step - loss: 0.7700 - accuracy: 0.6934\n",
      "Epoch: 2/5\n",
      "Processing rows: 0 - 4999\n",
      "157/157 [==============================] - 26s 169ms/step - loss: 0.6033 - accuracy: 0.6504\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.6932 - accuracy: 0.7186\n",
      "Processing rows: 5000 - 9999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 26s 163ms/step - loss: 0.6004 - accuracy: 0.6500\n",
      "82/82 [==============================] - 23s 275ms/step - loss: 0.6798 - accuracy: 0.7347\n",
      "Processing rows: 10000 - 14999\n",
      "157/157 [==============================] - 26s 162ms/step - loss: 0.6019 - accuracy: 0.6528\n",
      "83/83 [==============================] - 23s 276ms/step - loss: 0.6940 - accuracy: 0.7246\n",
      "Processing rows: 15000 - 19999\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.5932 - accuracy: 0.6560\n",
      "83/83 [==============================] - 23s 280ms/step - loss: 0.6744 - accuracy: 0.7323\n",
      "Processing rows: 20000 - 24999\n",
      "157/157 [==============================] - 27s 171ms/step - loss: 0.6026 - accuracy: 0.6510\n",
      "82/82 [==============================] - 23s 280ms/step - loss: 0.6478 - accuracy: 0.7320\n",
      "Processing rows: 25000 - 29999\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.5910 - accuracy: 0.6670\n",
      "81/81 [==============================] - 21s 258ms/step - loss: 0.6316 - accuracy: 0.7486\n",
      "Processing rows: 30000 - 34999\n",
      "157/157 [==============================] - 26s 165ms/step - loss: 0.5938 - accuracy: 0.6666\n",
      "83/83 [==============================] - 21s 256ms/step - loss: 0.6164 - accuracy: 0.7562\n",
      "Processing rows: 35000 - 39999\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.5792 - accuracy: 0.6816\n",
      "83/83 [==============================] - 22s 269ms/step - loss: 0.6145 - accuracy: 0.7619\n",
      "Processing rows: 40000 - 44999\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.5784 - accuracy: 0.6740\n",
      "84/84 [==============================] - 23s 277ms/step - loss: 0.6179 - accuracy: 0.7554\n",
      "Processing rows: 45000 - 49999\n",
      "157/157 [==============================] - 25s 162ms/step - loss: 0.5847 - accuracy: 0.6608\n",
      "82/82 [==============================] - 23s 276ms/step - loss: 0.5941 - accuracy: 0.7636\n",
      "Processing rows: 50000 - 54999\n",
      "157/157 [==============================] - 26s 163ms/step - loss: 0.5797 - accuracy: 0.6700\n",
      "83/83 [==============================] - 23s 277ms/step - loss: 0.5800 - accuracy: 0.7722\n",
      "Processing rows: 55000 - 59999\n",
      "157/157 [==============================] - 25s 162ms/step - loss: 0.5881 - accuracy: 0.6768\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.6237 - accuracy: 0.7455\n",
      "Processing rows: 60000 - 64999\n",
      "157/157 [==============================] - 26s 163ms/step - loss: 0.5709 - accuracy: 0.6894\n",
      "81/81 [==============================] - 22s 278ms/step - loss: 0.5864 - accuracy: 0.7624\n",
      "Processing rows: 65000 - 69999\n",
      "157/157 [==============================] - 25s 162ms/step - loss: 0.5807 - accuracy: 0.6712\n",
      "84/84 [==============================] - 23s 278ms/step - loss: 0.5864 - accuracy: 0.7683\n",
      "Processing rows: 70000 - 74999\n",
      "157/157 [==============================] - 26s 163ms/step - loss: 0.5907 - accuracy: 0.6652\n",
      "81/81 [==============================] - 20s 252ms/step - loss: 0.6071 - accuracy: 0.7627\n",
      "Processing rows: 75000 - 79999\n",
      "157/157 [==============================] - 25s 162ms/step - loss: 0.5789 - accuracy: 0.6742\n",
      "84/84 [==============================] - 22s 268ms/step - loss: 0.5426 - accuracy: 0.7970\n",
      "Processing rows: 80000 - 84999\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.5789 - accuracy: 0.6730\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.5424 - accuracy: 0.7897\n",
      "Processing rows: 85000 - 89999\n",
      "157/157 [==============================] - 25s 160ms/step - loss: 0.5805 - accuracy: 0.6692\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.6034 - accuracy: 0.7621\n",
      "Processing rows: 90000 - 94999\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.5756 - accuracy: 0.6738\n",
      "81/81 [==============================] - 22s 277ms/step - loss: 0.6168 - accuracy: 0.7527\n",
      "Processing rows: 95000 - 99999\n",
      "157/157 [==============================] - 25s 160ms/step - loss: 0.5741 - accuracy: 0.6812\n",
      "82/82 [==============================] - 23s 277ms/step - loss: 0.5901 - accuracy: 0.7591\n",
      "Processing rows: 100000 - 104999\n",
      "157/157 [==============================] - 26s 164ms/step - loss: 0.5733 - accuracy: 0.6778\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.5605 - accuracy: 0.7762\n",
      "Processing rows: 105000 - 109999\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.5618 - accuracy: 0.6850\n",
      "83/83 [==============================] - 23s 280ms/step - loss: 0.5847 - accuracy: 0.7761\n",
      "Processing rows: 110000 - 114999\n",
      "157/157 [==============================] - 27s 170ms/step - loss: 0.5557 - accuracy: 0.6900\n",
      "79/79 [==============================] - 22s 281ms/step - loss: 0.5564 - accuracy: 0.7865\n",
      "Processing rows: 115000 - 119999\n",
      "157/157 [==============================] - 26s 163ms/step - loss: 0.5696 - accuracy: 0.6718\n",
      "83/83 [==============================] - 21s 251ms/step - loss: 0.5730 - accuracy: 0.7747\n",
      "Processing rows: 120000 - 124999\n",
      "157/157 [==============================] - 26s 164ms/step - loss: 0.5653 - accuracy: 0.6896\n",
      "82/82 [==============================] - 22s 268ms/step - loss: 0.5756 - accuracy: 0.7766\n",
      "Processing rows: 125000 - 129999\n",
      "157/157 [==============================] - 26s 165ms/step - loss: 0.5530 - accuracy: 0.6954\n",
      "84/84 [==============================] - 23s 275ms/step - loss: 0.5708 - accuracy: 0.7721\n",
      "Processing rows: 130000 - 134999\n",
      "157/157 [==============================] - 25s 162ms/step - loss: 0.5503 - accuracy: 0.7066\n",
      "82/82 [==============================] - 23s 276ms/step - loss: 0.5469 - accuracy: 0.7943\n",
      "Processing rows: 135000 - 139999\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.5558 - accuracy: 0.6950\n",
      "82/82 [==============================] - 23s 280ms/step - loss: 0.5309 - accuracy: 0.7895\n",
      "Processing rows: 140000 - 144999\n",
      "157/157 [==============================] - 26s 167ms/step - loss: 0.5594 - accuracy: 0.6994\n",
      "82/82 [==============================] - 23s 281ms/step - loss: 0.5515 - accuracy: 0.7890\n",
      "Processing rows: 145000 - 149999\n",
      "157/157 [==============================] - 26s 168ms/step - loss: 0.5596 - accuracy: 0.6842\n",
      "83/83 [==============================] - 21s 258ms/step - loss: 0.5150 - accuracy: 0.7986\n",
      "Processing rows: 150000 - 154999\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.5657 - accuracy: 0.6816\n",
      "82/82 [==============================] - 22s 269ms/step - loss: 0.5360 - accuracy: 0.7912\n",
      "Processing rows: 155000 - 159999\n",
      "157/157 [==============================] - 27s 173ms/step - loss: 0.5661 - accuracy: 0.6760\n",
      "79/79 [==============================] - 22s 277ms/step - loss: 0.5293 - accuracy: 0.7905\n",
      "Processing rows: 160000 - 164999\n",
      "157/157 [==============================] - 24s 156ms/step - loss: 0.5514 - accuracy: 0.6918\n",
      "83/83 [==============================] - 23s 276ms/step - loss: 0.5365 - accuracy: 0.7931\n",
      "Processing rows: 165000 - 169999\n",
      "157/157 [==============================] - 26s 167ms/step - loss: 0.5620 - accuracy: 0.6962\n",
      "82/82 [==============================] - 22s 274ms/step - loss: 0.5591 - accuracy: 0.7851\n",
      "Processing rows: 170000 - 174999\n",
      "157/157 [==============================] - 25s 158ms/step - loss: 0.5481 - accuracy: 0.6960\n",
      "83/83 [==============================] - 23s 275ms/step - loss: 0.5273 - accuracy: 0.7853\n",
      "Processing rows: 175000 - 179999\n",
      "157/157 [==============================] - 26s 164ms/step - loss: 0.5656 - accuracy: 0.6850\n",
      "83/83 [==============================] - 23s 275ms/step - loss: 0.5587 - accuracy: 0.7913\n",
      "Processing rows: 180000 - 183484\n",
      "109/109 [==============================] - 17s 158ms/step - loss: 0.5786 - accuracy: 0.6660\n",
      "57/57 [==============================] - 16s 277ms/step - loss: 0.5790 - accuracy: 0.7753\n",
      "Epoch: 3/5\n",
      "Processing rows: 0 - 4999\n",
      "157/157 [==============================] - 26s 164ms/step - loss: 0.5532 - accuracy: 0.6932\n",
      "81/81 [==============================] - 23s 278ms/step - loss: 0.4917 - accuracy: 0.8179\n",
      "Processing rows: 5000 - 9999\n",
      "157/157 [==============================] - 25s 158ms/step - loss: 0.5465 - accuracy: 0.6902\n",
      "82/82 [==============================] - 23s 276ms/step - loss: 0.4873 - accuracy: 0.8114\n",
      "Processing rows: 10000 - 14999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 26s 163ms/step - loss: 0.5430 - accuracy: 0.7008\n",
      "83/83 [==============================] - 23s 275ms/step - loss: 0.5014 - accuracy: 0.8017\n",
      "Processing rows: 15000 - 19999\n",
      "157/157 [==============================] - 25s 158ms/step - loss: 0.5335 - accuracy: 0.7134\n",
      "83/83 [==============================] - 23s 275ms/step - loss: 0.4671 - accuracy: 0.8206\n",
      "Processing rows: 20000 - 24999\n",
      "157/157 [==============================] - 26s 163ms/step - loss: 0.5429 - accuracy: 0.6992\n",
      "82/82 [==============================] - 23s 278ms/step - loss: 0.4210 - accuracy: 0.8435\n",
      "Processing rows: 25000 - 29999\n",
      "157/157 [==============================] - 25s 159ms/step - loss: 0.5301 - accuracy: 0.7092\n",
      "81/81 [==============================] - 20s 252ms/step - loss: 0.4141 - accuracy: 0.8353\n",
      "Processing rows: 30000 - 34999\n",
      "157/157 [==============================] - 26s 163ms/step - loss: 0.5385 - accuracy: 0.7086\n",
      "83/83 [==============================] - 21s 251ms/step - loss: 0.4238 - accuracy: 0.8362\n",
      "Processing rows: 35000 - 39999\n",
      "157/157 [==============================] - 26s 163ms/step - loss: 0.5173 - accuracy: 0.7268\n",
      "83/83 [==============================] - 22s 267ms/step - loss: 0.4003 - accuracy: 0.8460\n",
      "Processing rows: 40000 - 44999\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.5148 - accuracy: 0.7324\n",
      "84/84 [==============================] - 23s 279ms/step - loss: 0.3870 - accuracy: 0.8562\n",
      "Processing rows: 45000 - 49999\n",
      "157/157 [==============================] - 26s 164ms/step - loss: 0.5269 - accuracy: 0.7130\n",
      "82/82 [==============================] - 23s 275ms/step - loss: 0.3708 - accuracy: 0.8544\n",
      "Processing rows: 50000 - 54999\n",
      "157/157 [==============================] - 25s 162ms/step - loss: 0.5198 - accuracy: 0.7212\n",
      "83/83 [==============================] - 23s 275ms/step - loss: 0.3687 - accuracy: 0.8600\n",
      "Processing rows: 55000 - 59999\n",
      "157/157 [==============================] - 26s 162ms/step - loss: 0.5293 - accuracy: 0.7190\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.4242 - accuracy: 0.8365\n",
      "Processing rows: 60000 - 64999\n",
      "157/157 [==============================] - 26s 162ms/step - loss: 0.5124 - accuracy: 0.7350\n",
      "81/81 [==============================] - 23s 278ms/step - loss: 0.3800 - accuracy: 0.8506\n",
      "Processing rows: 65000 - 69999\n",
      "157/157 [==============================] - 25s 161ms/step - loss: 0.5221 - accuracy: 0.7176\n",
      "84/84 [==============================] - 23s 275ms/step - loss: 0.3693 - accuracy: 0.8515\n",
      "Processing rows: 70000 - 74999\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.5437 - accuracy: 0.6952\n",
      "81/81 [==============================] - 21s 258ms/step - loss: 0.3980 - accuracy: 0.8469\n",
      "Processing rows: 75000 - 79999\n",
      "157/157 [==============================] - 26s 167ms/step - loss: 0.5252 - accuracy: 0.7212\n",
      "84/84 [==============================] - 23s 270ms/step - loss: 0.3174 - accuracy: 0.8721\n",
      "Processing rows: 80000 - 84999\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.5218 - accuracy: 0.7208\n",
      "81/81 [==============================] - 23s 281ms/step - loss: 0.3049 - accuracy: 0.8807\n",
      "Processing rows: 85000 - 89999\n",
      "157/157 [==============================] - 26s 165ms/step - loss: 0.5254 - accuracy: 0.7164\n",
      "81/81 [==============================] - 23s 280ms/step - loss: 0.3728 - accuracy: 0.8559\n",
      "Processing rows: 90000 - 94999\n",
      "157/157 [==============================] - 26s 167ms/step - loss: 0.5168 - accuracy: 0.7246\n",
      "81/81 [==============================] - 23s 281ms/step - loss: 0.3882 - accuracy: 0.8498\n",
      "Processing rows: 95000 - 99999\n",
      "157/157 [==============================] - 25s 162ms/step - loss: 0.5171 - accuracy: 0.7282\n",
      "82/82 [==============================] - 23s 281ms/step - loss: 0.3937 - accuracy: 0.8509\n",
      "Processing rows: 100000 - 104999\n",
      "157/157 [==============================] - 25s 161ms/step - loss: 0.5142 - accuracy: 0.7258\n",
      "81/81 [==============================] - 23s 280ms/step - loss: 0.3521 - accuracy: 0.8626\n",
      "Processing rows: 105000 - 109999\n",
      "157/157 [==============================] - 25s 161ms/step - loss: 0.5038 - accuracy: 0.7322\n",
      "83/83 [==============================] - 23s 281ms/step - loss: 0.3696 - accuracy: 0.8613\n",
      "Processing rows: 110000 - 114999\n",
      "157/157 [==============================] - 25s 161ms/step - loss: 0.4928 - accuracy: 0.7428\n",
      "79/79 [==============================] - 22s 281ms/step - loss: 0.3415 - accuracy: 0.8682\n",
      "Processing rows: 115000 - 119999\n",
      "157/157 [==============================] - 25s 159ms/step - loss: 0.5191 - accuracy: 0.7198\n",
      "83/83 [==============================] - 21s 258ms/step - loss: 0.3418 - accuracy: 0.8671\n",
      "Processing rows: 120000 - 124999\n",
      "157/157 [==============================] - 24s 155ms/step - loss: 0.4943 - accuracy: 0.7378\n",
      "82/82 [==============================] - 22s 268ms/step - loss: 0.3456 - accuracy: 0.8637\n",
      "Processing rows: 125000 - 129999\n",
      "157/157 [==============================] - 25s 157ms/step - loss: 0.4986 - accuracy: 0.7332\n",
      "84/84 [==============================] - 23s 275ms/step - loss: 0.3634 - accuracy: 0.8615\n",
      "Processing rows: 130000 - 134999\n",
      "157/157 [==============================] - 25s 157ms/step - loss: 0.4977 - accuracy: 0.7442\n",
      "82/82 [==============================] - 23s 278ms/step - loss: 0.3567 - accuracy: 0.8632\n",
      "Processing rows: 135000 - 139999\n",
      "157/157 [==============================] - 24s 156ms/step - loss: 0.4922 - accuracy: 0.7456\n",
      "82/82 [==============================] - 23s 275ms/step - loss: 0.3404 - accuracy: 0.8637\n",
      "Processing rows: 140000 - 144999\n",
      "157/157 [==============================] - 25s 156ms/step - loss: 0.5059 - accuracy: 0.7400\n",
      "82/82 [==============================] - 23s 276ms/step - loss: 0.3305 - accuracy: 0.8709\n",
      "Processing rows: 145000 - 149999\n",
      "157/157 [==============================] - 24s 155ms/step - loss: 0.5043 - accuracy: 0.7326\n",
      "83/83 [==============================] - 21s 253ms/step - loss: 0.2854 - accuracy: 0.8916\n",
      "Processing rows: 150000 - 154999\n",
      "157/157 [==============================] - 26s 163ms/step - loss: 0.5182 - accuracy: 0.7204\n",
      "82/82 [==============================] - 22s 269ms/step - loss: 0.3109 - accuracy: 0.8808\n",
      "Processing rows: 155000 - 159999\n",
      "157/157 [==============================] - 25s 161ms/step - loss: 0.5197 - accuracy: 0.7256\n",
      "79/79 [==============================] - 22s 281ms/step - loss: 0.3191 - accuracy: 0.8772\n",
      "Processing rows: 160000 - 164999\n",
      "157/157 [==============================] - 25s 156ms/step - loss: 0.4955 - accuracy: 0.7416\n",
      "83/83 [==============================] - 23s 278ms/step - loss: 0.3052 - accuracy: 0.8828\n",
      "Processing rows: 165000 - 169999\n",
      "157/157 [==============================] - 25s 156ms/step - loss: 0.5092 - accuracy: 0.7288\n",
      "82/82 [==============================] - 23s 275ms/step - loss: 0.3208 - accuracy: 0.8806\n",
      "Processing rows: 170000 - 174999\n",
      "157/157 [==============================] - 25s 156ms/step - loss: 0.5007 - accuracy: 0.7368\n",
      "83/83 [==============================] - 23s 276ms/step - loss: 0.2979 - accuracy: 0.8849\n",
      "Processing rows: 175000 - 179999\n",
      "157/157 [==============================] - 25s 157ms/step - loss: 0.5165 - accuracy: 0.7132\n",
      "83/83 [==============================] - 23s 277ms/step - loss: 0.3327 - accuracy: 0.8703\n",
      "Processing rows: 180000 - 183484\n",
      "109/109 [==============================] - 17s 156ms/step - loss: 0.5324 - accuracy: 0.7110\n",
      "57/57 [==============================] - 15s 258ms/step - loss: 0.3635 - accuracy: 0.8550\n",
      "Epoch: 4/5\n",
      "Processing rows: 0 - 4999\n",
      "157/157 [==============================] - 25s 157ms/step - loss: 0.5085 - accuracy: 0.7250\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.3059 - accuracy: 0.8786\n",
      "Processing rows: 5000 - 9999\n",
      "157/157 [==============================] - 25s 156ms/step - loss: 0.4977 - accuracy: 0.7288\n",
      "82/82 [==============================] - 23s 276ms/step - loss: 0.2752 - accuracy: 0.8936\n",
      "Processing rows: 10000 - 14999\n",
      "157/157 [==============================] - 25s 159ms/step - loss: 0.4976 - accuracy: 0.7328\n",
      "83/83 [==============================] - 23s 274ms/step - loss: 0.3255 - accuracy: 0.8682\n",
      "Processing rows: 15000 - 19999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 24s 156ms/step - loss: 0.4810 - accuracy: 0.7422\n",
      "83/83 [==============================] - 23s 276ms/step - loss: 0.2549 - accuracy: 0.9010\n",
      "Processing rows: 20000 - 24999\n",
      "157/157 [==============================] - 24s 156ms/step - loss: 0.4931 - accuracy: 0.7388\n",
      "82/82 [==============================] - 22s 274ms/step - loss: 0.2435 - accuracy: 0.9043\n",
      "Processing rows: 25000 - 29999\n",
      "157/157 [==============================] - 25s 156ms/step - loss: 0.4841 - accuracy: 0.7470\n",
      "81/81 [==============================] - 20s 252ms/step - loss: 0.2190 - accuracy: 0.9176\n",
      "Processing rows: 30000 - 34999\n",
      "157/157 [==============================] - 24s 156ms/step - loss: 0.4847 - accuracy: 0.7440\n",
      "83/83 [==============================] - 21s 250ms/step - loss: 0.2480 - accuracy: 0.9113\n",
      "Processing rows: 35000 - 39999\n",
      "157/157 [==============================] - 25s 157ms/step - loss: 0.4555 - accuracy: 0.7682\n",
      "83/83 [==============================] - 22s 268ms/step - loss: 0.2360 - accuracy: 0.9147\n",
      "Processing rows: 40000 - 44999\n",
      "157/157 [==============================] - 25s 159ms/step - loss: 0.4609 - accuracy: 0.7660\n",
      "84/84 [==============================] - 23s 280ms/step - loss: 0.2234 - accuracy: 0.9175\n",
      "Processing rows: 45000 - 49999\n",
      "157/157 [==============================] - 25s 159ms/step - loss: 0.4755 - accuracy: 0.7484\n",
      "82/82 [==============================] - 23s 278ms/step - loss: 0.2007 - accuracy: 0.9272\n",
      "Processing rows: 50000 - 54999\n",
      "157/157 [==============================] - 24s 156ms/step - loss: 0.4703 - accuracy: 0.7500\n",
      "83/83 [==============================] - 23s 274ms/step - loss: 0.2126 - accuracy: 0.9148\n",
      "Processing rows: 55000 - 59999\n",
      "157/157 [==============================] - 25s 156ms/step - loss: 0.4740 - accuracy: 0.7490\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.2690 - accuracy: 0.8989\n",
      "Processing rows: 60000 - 64999\n",
      "157/157 [==============================] - 24s 156ms/step - loss: 0.4608 - accuracy: 0.7690\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.2265 - accuracy: 0.9156\n",
      "Processing rows: 65000 - 69999\n",
      "157/157 [==============================] - 24s 156ms/step - loss: 0.4640 - accuracy: 0.7622\n",
      "84/84 [==============================] - 24s 282ms/step - loss: 0.2290 - accuracy: 0.9119\n",
      "Processing rows: 70000 - 74999\n",
      "157/157 [==============================] - 25s 158ms/step - loss: 0.4900 - accuracy: 0.7406\n",
      "81/81 [==============================] - 21s 258ms/step - loss: 0.2384 - accuracy: 0.9099\n",
      "Processing rows: 75000 - 79999\n",
      "157/157 [==============================] - 25s 159ms/step - loss: 0.4649 - accuracy: 0.7624\n",
      "84/84 [==============================] - 22s 268ms/step - loss: 0.1871 - accuracy: 0.9305\n",
      "Processing rows: 80000 - 84999\n",
      "157/157 [==============================] - 25s 161ms/step - loss: 0.4714 - accuracy: 0.7594\n",
      "81/81 [==============================] - 23s 280ms/step - loss: 0.1841 - accuracy: 0.9314\n",
      "Processing rows: 85000 - 89999\n",
      "157/157 [==============================] - 25s 159ms/step - loss: 0.4756 - accuracy: 0.7466\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.2439 - accuracy: 0.9066\n",
      "Processing rows: 90000 - 94999\n",
      "157/157 [==============================] - 25s 156ms/step - loss: 0.4724 - accuracy: 0.7500\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.2391 - accuracy: 0.9094\n",
      "Processing rows: 95000 - 99999\n",
      "157/157 [==============================] - 24s 156ms/step - loss: 0.4708 - accuracy: 0.7570\n",
      "82/82 [==============================] - 23s 276ms/step - loss: 0.2337 - accuracy: 0.9124\n",
      "Processing rows: 100000 - 104999\n",
      "157/157 [==============================] - 25s 156ms/step - loss: 0.4714 - accuracy: 0.7596\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.2171 - accuracy: 0.9144\n",
      "Processing rows: 105000 - 109999\n",
      "157/157 [==============================] - 24s 156ms/step - loss: 0.4719 - accuracy: 0.7598\n",
      "83/83 [==============================] - 23s 274ms/step - loss: 0.2180 - accuracy: 0.9246\n",
      "Processing rows: 110000 - 114999\n",
      "157/157 [==============================] - 25s 156ms/step - loss: 0.4484 - accuracy: 0.7680\n",
      "79/79 [==============================] - 22s 276ms/step - loss: 0.1999 - accuracy: 0.9279\n",
      "Processing rows: 115000 - 119999\n",
      "157/157 [==============================] - 26s 163ms/step - loss: 0.4691 - accuracy: 0.7526\n",
      "83/83 [==============================] - 22s 259ms/step - loss: 0.2337 - accuracy: 0.9163\n",
      "Processing rows: 120000 - 124999\n",
      "157/157 [==============================] - 25s 159ms/step - loss: 0.4242 - accuracy: 0.7854\n",
      "82/82 [==============================] - 22s 269ms/step - loss: 0.2208 - accuracy: 0.9133\n",
      "Processing rows: 125000 - 129999\n",
      "157/157 [==============================] - 25s 158ms/step - loss: 0.4491 - accuracy: 0.7714\n",
      "84/84 [==============================] - 23s 276ms/step - loss: 0.1839 - accuracy: 0.9313\n",
      "Processing rows: 130000 - 134999\n",
      "157/157 [==============================] - 25s 156ms/step - loss: 0.4532 - accuracy: 0.7668\n",
      "82/82 [==============================] - 23s 276ms/step - loss: 0.2279 - accuracy: 0.9103\n",
      "Processing rows: 135000 - 139999\n",
      "157/157 [==============================] - 25s 158ms/step - loss: 0.4444 - accuracy: 0.7720\n",
      "82/82 [==============================] - 22s 274ms/step - loss: 0.2129 - accuracy: 0.9149\n",
      "Processing rows: 140000 - 144999\n",
      "157/157 [==============================] - 25s 156ms/step - loss: 0.4662 - accuracy: 0.7638\n",
      "82/82 [==============================] - 23s 276ms/step - loss: 0.2078 - accuracy: 0.9188\n",
      "Processing rows: 145000 - 149999\n",
      "157/157 [==============================] - 25s 162ms/step - loss: 0.4297 - accuracy: 0.7874\n",
      "83/83 [==============================] - 21s 258ms/step - loss: 0.1735 - accuracy: 0.9373\n",
      "Processing rows: 150000 - 154999\n",
      "157/157 [==============================] - 25s 159ms/step - loss: 0.4761 - accuracy: 0.7470\n",
      "82/82 [==============================] - 22s 269ms/step - loss: 0.1777 - accuracy: 0.9369\n",
      "Processing rows: 155000 - 159999\n",
      "157/157 [==============================] - 26s 165ms/step - loss: 0.4814 - accuracy: 0.7466\n",
      "79/79 [==============================] - 22s 280ms/step - loss: 0.2269 - accuracy: 0.9180\n",
      "Processing rows: 160000 - 164999\n",
      "157/157 [==============================] - 25s 160ms/step - loss: 0.4488 - accuracy: 0.7730\n",
      "83/83 [==============================] - 23s 277ms/step - loss: 0.1799 - accuracy: 0.9293\n",
      "Processing rows: 165000 - 169999\n",
      "157/157 [==============================] - 25s 158ms/step - loss: 0.4617 - accuracy: 0.7638\n",
      "82/82 [==============================] - 23s 276ms/step - loss: 0.1864 - accuracy: 0.9310\n",
      "Processing rows: 170000 - 174999\n",
      "157/157 [==============================] - 25s 156ms/step - loss: 0.4606 - accuracy: 0.7688\n",
      "83/83 [==============================] - 23s 274ms/step - loss: 0.1724 - accuracy: 0.9320\n",
      "Processing rows: 175000 - 179999\n",
      "157/157 [==============================] - 25s 158ms/step - loss: 0.4754 - accuracy: 0.7474\n",
      "83/83 [==============================] - 23s 277ms/step - loss: 0.1953 - accuracy: 0.9293\n",
      "Processing rows: 180000 - 183484\n",
      "109/109 [==============================] - 17s 157ms/step - loss: 0.4921 - accuracy: 0.7366\n",
      "57/57 [==============================] - 16s 276ms/step - loss: 0.2040 - accuracy: 0.9181\n",
      "Epoch: 5/5\n",
      "Processing rows: 0 - 4999\n",
      "157/157 [==============================] - 25s 160ms/step - loss: 0.4630 - accuracy: 0.7566\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.1940 - accuracy: 0.9304\n",
      "Processing rows: 5000 - 9999\n",
      "157/157 [==============================] - 25s 157ms/step - loss: 0.4471 - accuracy: 0.7612\n",
      "82/82 [==============================] - 23s 275ms/step - loss: 0.1811 - accuracy: 0.9383\n",
      "Processing rows: 10000 - 14999\n",
      "157/157 [==============================] - 26s 164ms/step - loss: 0.4542 - accuracy: 0.7612\n",
      "83/83 [==============================] - 23s 276ms/step - loss: 0.1695 - accuracy: 0.9305\n",
      "Processing rows: 15000 - 19999\n",
      "157/157 [==============================] - 25s 158ms/step - loss: 0.4455 - accuracy: 0.7672\n",
      "83/83 [==============================] - 23s 274ms/step - loss: 0.1467 - accuracy: 0.9520\n",
      "Processing rows: 20000 - 24999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 25s 160ms/step - loss: 0.4490 - accuracy: 0.7630\n",
      "82/82 [==============================] - 23s 275ms/step - loss: 0.1463 - accuracy: 0.9450\n",
      "Processing rows: 25000 - 29999\n",
      "157/157 [==============================] - 25s 159ms/step - loss: 0.4418 - accuracy: 0.7716\n",
      "81/81 [==============================] - 20s 252ms/step - loss: 0.1436 - accuracy: 0.9482\n",
      "Processing rows: 30000 - 34999\n",
      "157/157 [==============================] - 25s 160ms/step - loss: 0.4425 - accuracy: 0.7714\n",
      "83/83 [==============================] - 21s 251ms/step - loss: 0.1615 - accuracy: 0.9367\n",
      "Processing rows: 35000 - 39999\n",
      "157/157 [==============================] - 24s 156ms/step - loss: 0.4265 - accuracy: 0.7836\n",
      "83/83 [==============================] - 22s 268ms/step - loss: 0.1712 - accuracy: 0.9426\n",
      "Processing rows: 40000 - 44999\n",
      "157/157 [==============================] - 25s 162ms/step - loss: 0.4220 - accuracy: 0.7908\n",
      "84/84 [==============================] - 23s 277ms/step - loss: 0.1603 - accuracy: 0.9459\n",
      "Processing rows: 45000 - 49999\n",
      "157/157 [==============================] - 26s 163ms/step - loss: 0.4248 - accuracy: 0.7808\n",
      "82/82 [==============================] - 23s 280ms/step - loss: 0.1223 - accuracy: 0.9544\n",
      "Processing rows: 50000 - 54999\n",
      "157/157 [==============================] - 26s 163ms/step - loss: 0.4179 - accuracy: 0.7934\n",
      "83/83 [==============================] - 23s 276ms/step - loss: 0.1338 - accuracy: 0.9517\n",
      "Processing rows: 55000 - 59999\n",
      "157/157 [==============================] - 25s 159ms/step - loss: 0.4017 - accuracy: 0.8054\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.1845 - accuracy: 0.9352\n",
      "Processing rows: 60000 - 64999\n",
      "157/157 [==============================] - 25s 157ms/step - loss: 0.3884 - accuracy: 0.8074\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.1601 - accuracy: 0.9392\n",
      "Processing rows: 65000 - 69999\n",
      "157/157 [==============================] - 25s 158ms/step - loss: 0.4140 - accuracy: 0.7894\n",
      "84/84 [==============================] - 23s 279ms/step - loss: 0.1605 - accuracy: 0.9464\n",
      "Processing rows: 70000 - 74999\n",
      "157/157 [==============================] - 25s 158ms/step - loss: 0.4273 - accuracy: 0.7756\n",
      "81/81 [==============================] - 20s 252ms/step - loss: 0.1606 - accuracy: 0.9443\n",
      "Processing rows: 75000 - 79999\n",
      "157/157 [==============================] - 25s 160ms/step - loss: 0.4013 - accuracy: 0.8034\n",
      "84/84 [==============================] - 23s 269ms/step - loss: 0.1496 - accuracy: 0.9424\n",
      "Processing rows: 80000 - 84999\n",
      "157/157 [==============================] - 26s 164ms/step - loss: 0.4248 - accuracy: 0.7858\n",
      "81/81 [==============================] - 23s 279ms/step - loss: 0.1315 - accuracy: 0.9543\n",
      "Processing rows: 85000 - 89999\n",
      "157/157 [==============================] - 25s 159ms/step - loss: 0.4338 - accuracy: 0.7748\n",
      "81/81 [==============================] - 23s 280ms/step - loss: 0.1735 - accuracy: 0.9368\n",
      "Processing rows: 90000 - 94999\n",
      "157/157 [==============================] - 25s 159ms/step - loss: 0.4312 - accuracy: 0.7774\n",
      "81/81 [==============================] - 22s 277ms/step - loss: 0.1697 - accuracy: 0.9400\n",
      "Processing rows: 95000 - 99999\n",
      "157/157 [==============================] - 25s 156ms/step - loss: 0.4315 - accuracy: 0.7794\n",
      "82/82 [==============================] - 23s 276ms/step - loss: 0.1914 - accuracy: 0.9312\n",
      "Processing rows: 100000 - 104999\n",
      "157/157 [==============================] - 25s 158ms/step - loss: 0.4250 - accuracy: 0.7890\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.1440 - accuracy: 0.9489\n",
      "Processing rows: 105000 - 109999\n",
      "157/157 [==============================] - 25s 156ms/step - loss: 0.4203 - accuracy: 0.7912\n",
      "83/83 [==============================] - 23s 274ms/step - loss: 0.1633 - accuracy: 0.9435\n",
      "Processing rows: 110000 - 114999\n",
      "157/157 [==============================] - 25s 161ms/step - loss: 0.4062 - accuracy: 0.7994\n",
      "79/79 [==============================] - 20s 258ms/step - loss: 0.1375 - accuracy: 0.9542\n",
      "Processing rows: 115000 - 119999\n",
      "157/157 [==============================] - 25s 159ms/step - loss: 0.4302 - accuracy: 0.7812\n",
      "83/83 [==============================] - 22s 269ms/step - loss: 0.1512 - accuracy: 0.9451\n",
      "Processing rows: 120000 - 124999\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.3700 - accuracy: 0.8204\n",
      "82/82 [==============================] - 23s 279ms/step - loss: 0.1497 - accuracy: 0.9504\n",
      "Processing rows: 125000 - 129999\n",
      "157/157 [==============================] - 25s 162ms/step - loss: 0.4063 - accuracy: 0.8032\n",
      "84/84 [==============================] - 23s 275ms/step - loss: 0.1096 - accuracy: 0.9621\n",
      "Processing rows: 130000 - 134999\n",
      "157/157 [==============================] - 25s 158ms/step - loss: 0.4148 - accuracy: 0.7928\n",
      "82/82 [==============================] - 23s 277ms/step - loss: 0.1434 - accuracy: 0.9464\n",
      "Processing rows: 135000 - 139999\n",
      "157/157 [==============================] - 25s 157ms/step - loss: 0.4085 - accuracy: 0.8010\n",
      "82/82 [==============================] - 23s 276ms/step - loss: 0.1766 - accuracy: 0.9411\n",
      "Processing rows: 140000 - 144999\n",
      "157/157 [==============================] - 25s 161ms/step - loss: 0.4313 - accuracy: 0.7826\n",
      "82/82 [==============================] - 23s 275ms/step - loss: 0.1768 - accuracy: 0.9330\n",
      "Processing rows: 145000 - 149999\n",
      "157/157 [==============================] - 26s 164ms/step - loss: 0.3255 - accuracy: 0.8548\n",
      "83/83 [==============================] - 23s 281ms/step - loss: 0.1238 - accuracy: 0.9547\n",
      "Processing rows: 150000 - 154999\n",
      "157/157 [==============================] - 26s 163ms/step - loss: 0.4288 - accuracy: 0.7750\n",
      "82/82 [==============================] - 23s 280ms/step - loss: 0.1272 - accuracy: 0.9569\n",
      "Processing rows: 155000 - 159999\n",
      "157/157 [==============================] - 25s 159ms/step - loss: 0.4376 - accuracy: 0.7750\n",
      "79/79 [==============================] - 22s 282ms/step - loss: 0.1560 - accuracy: 0.9438\n",
      "Processing rows: 160000 - 164999\n",
      "157/157 [==============================] - 25s 161ms/step - loss: 0.4171 - accuracy: 0.7926\n",
      "83/83 [==============================] - 23s 279ms/step - loss: 0.1247 - accuracy: 0.9535\n",
      "Processing rows: 165000 - 169999\n",
      "157/157 [==============================] - 25s 160ms/step - loss: 0.4351 - accuracy: 0.7824\n",
      "82/82 [==============================] - 23s 279ms/step - loss: 0.1158 - accuracy: 0.9569\n",
      "Processing rows: 170000 - 174999\n",
      "157/157 [==============================] - 25s 162ms/step - loss: 0.4212 - accuracy: 0.7946\n",
      "83/83 [==============================] - 23s 280ms/step - loss: 0.1285 - accuracy: 0.9544\n",
      "Processing rows: 175000 - 179999\n",
      "157/157 [==============================] - 25s 160ms/step - loss: 0.4393 - accuracy: 0.7692\n",
      "83/83 [==============================] - 23s 281ms/step - loss: 0.1337 - accuracy: 0.9483\n",
      "Processing rows: 180000 - 183484\n",
      "109/109 [==============================] - 17s 159ms/step - loss: 0.4415 - accuracy: 0.7664\n",
      "57/57 [==============================] - 15s 257ms/step - loss: 0.1451 - accuracy: 0.9485\n",
      "Success!\n",
      "Testing...\n",
      "Processing rows: 0 - 4999\n",
      "157/157 [==============================] - 6s 35ms/step\n",
      "89/89 [==============================] - 5s 53ms/step\n",
      "[0 1 2 3 4]\n",
      "[0 1]\n",
      "[0 1 2 3]\n",
      "Processing rows: 5000 - 9999\n",
      "157/157 [==============================] - 5s 35ms/step\n",
      "88/88 [==============================] - 5s 53ms/step\n",
      "[0 1 2 3 4]\n",
      "[0 1]\n",
      "[0 1 2 3]\n",
      "Processing rows: 10000 - 14999\n",
      "157/157 [==============================] - 5s 35ms/step\n",
      "86/86 [==============================] - 5s 53ms/step\n",
      "[0 1 2 3 4]\n",
      "[0 1]\n",
      "[0 1 2 3]\n",
      "Processing rows: 15000 - 19999\n",
      "157/157 [==============================] - 5s 35ms/step\n",
      "88/88 [==============================] - 5s 53ms/step\n",
      "[0 1 2 3 4]\n",
      "[0 1]\n",
      "[0 1 2 3]\n",
      "Processing rows: 20000 - 24999\n",
      "157/157 [==============================] - 5s 35ms/step\n",
      "89/89 [==============================] - 4s 48ms/step\n",
      "[0 1 2 3 4]\n",
      "[0 1]\n",
      "[0 1 2 3]\n",
      "Processing rows: 25000 - 29999\n",
      "157/157 [==============================] - 6s 35ms/step\n",
      "87/87 [==============================] - 5s 53ms/step\n",
      "[0 1 2 3 4]\n",
      "[0 1]\n",
      "[0 1 2 3]\n",
      "Processing rows: 30000 - 34999\n",
      "157/157 [==============================] - 5s 35ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 5s 53ms/step\n",
      "[0 1 2 3 4]\n",
      "[0 1]\n",
      "[0 1 2 3]\n",
      "Processing rows: 35000 - 39999\n",
      "157/157 [==============================] - 5s 34ms/step\n",
      "88/88 [==============================] - 4s 47ms/step\n",
      "[0 1 2 3 4]\n",
      "[0 1]\n",
      "[0 1 2 3]\n",
      "Processing rows: 40000 - 44999\n",
      "157/157 [==============================] - 5s 34ms/step\n",
      "86/86 [==============================] - 4s 52ms/step\n",
      "[0 1 2 3 4]\n",
      "[0 1]\n",
      "[0 1 2 3]\n",
      "Processing rows: 45000 - 49999\n",
      "157/157 [==============================] - 5s 34ms/step\n",
      "87/87 [==============================] - 5s 52ms/step\n",
      "[0 1 2 3 4]\n",
      "[0 1]\n",
      "[0 1 2 3]\n",
      "Processing rows: 50000 - 54999\n",
      "157/157 [==============================] - 5s 34ms/step\n",
      "87/87 [==============================] - 5s 52ms/step\n",
      "[0 1 2 3 4]\n",
      "[0 1]\n",
      "[0 1 2 3]\n",
      "Processing rows: 55000 - 59999\n",
      "157/157 [==============================] - 5s 34ms/step\n",
      "89/89 [==============================] - 4s 47ms/step\n",
      "[0 1 2 3 4]\n",
      "[0 1]\n",
      "[0 1 2 3]\n",
      "Processing rows: 60000 - 64999\n",
      "157/157 [==============================] - 5s 34ms/step\n",
      "88/88 [==============================] - 4s 47ms/step\n",
      "[0 1 2 3 4]\n",
      "[0 1]\n",
      "[0 1 2 3]\n",
      "Processing rows: 65000 - 69999\n",
      "157/157 [==============================] - 5s 34ms/step\n",
      "86/86 [==============================] - 4s 51ms/step\n",
      "[0 1 2 3 4]\n",
      "[0 1]\n",
      "[0 1 2 3]\n",
      "Processing rows: 70000 - 74999\n",
      "157/157 [==============================] - 5s 34ms/step\n",
      "88/88 [==============================] - 5s 51ms/step\n",
      "[0 1 2 3 4]\n",
      "[0 1]\n",
      "[0 1 2 3]\n",
      "Processing rows: 75000 - 78636\n",
      "114/114 [==============================] - 4s 34ms/step\n",
      "65/65 [==============================] - 3s 51ms/step\n",
      "[0 1 2 3 4]\n",
      "[0 1]\n",
      "[0 1 2 3]\n",
      "Success!\n",
      "RESULTS:\n",
      "accuracy = 0.5329552246398006\n",
      "balanced accuracy = 0.5089186429107216\n",
      "f1 score = 0.5391173053706446\n"
     ]
    }
   ],
   "source": [
    "clf_cnn2_g_norm = CNN2Step(max_words * emb_glove.embedding_size, len(genres), optimizer, indiv_genre_label)\n",
    "train_and_save_results(emb_glove, clf_cnn2_g_norm, \n",
    "                       train_data.normalized_lyrics, train_data.genre, test_data.normalized_lyrics, test_data.genre, \n",
    "                       dataset_name, label_encoder, epochs=cnn_epochs, fname_end='_norm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_wv = Word2vec(max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_cnn_w_nn = CNN(max_words * emb_wv.embedding_size, len(genres), 'adam')\n",
    "train_and_save_results(emb_wv, clf_cnn_w_nn, \n",
    "                       train_data.lyrics, train_data.genre, test_data.lyrics, test_data.genre, \n",
    "                       dataset_name, label_encoder, epochs=cnn_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_cnn_w = CNN(max_words * emb_wv.embedding_size, len(genres), 'adam')\n",
    "train_and_save_results(emb_wv, clf_cnn_w, \n",
    "                       train_data.normalized_lyrics, train_data.genre, test_data.normalized_lyrics, test_data.genre, \n",
    "                       dataset_name, label_encoder, epochs=cnn_epochs, fname_end='_norm')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "cf3867dc7eb6b74b717291f53998e39b1c4928e27b652817468199b3aea2c37e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
